# Python学习笔记
## 这种方式记笔记可能会很轻松，开篇试试吧





# Get System Arguments 获取系统参数

```python
import sys

# 输出文件名
print sys.argv[0]

# 输出第一个参数
sys.argv[1]
```





# Define a class 定义类

```
class Person():
    self.name = ''
    self.id = 0
    self.father = 1
    self.mother = 2 

    def __init__(self, name):
        self.name = name
	self.born()
    
    def born(self):
        self.id = self.father + self.mother

me = Person('Solomon')
print me.id
```





# FLask 初接触
> Flask是基于Python的Web后台服务器框架，相对于Django来讲属于非常灵巧的轻量级框架。目前市面上应用程度很广，值得学习一下。

## Installation

- Windows Git Bash

```
pip install virtualenv
mkdir /d/workspace/myFlask
cd /d/workspace/myFlask

virtualenv --no-site-packages venv
source venv/Scripts/activate
# Now is already in virtual enviroment

pip install Flask
```

- Windows CMD

```
# 其他都一样 只有运行不同
venv\Scripts\activate
```

## Deployment

```
touch hello.py
mkdir static
mkdir templates
```

## Hello World

在hello.py中输入以下内容并保存(最简单Flask)

```
from flask import Flask
app = Flask(__name__)

@app.route('/')
def hello_world():
    return 'Hello World!'

    if __name__ == '__main__':
        app.run(debug=True)
```

## 运行

```
python hello.py
```

## 渲染模板

在`template`文件夹中新建模板users.html，并随便写几句话，在hello.py中加入如下语句：

```
#记住在前面需要引用渲染函数
from flask import render_template

@app.route('/users/')
def show_users():
    return render_template('users.html') 
```







# python 获取当前路径
> 看似是个小问题，但是在python里实际上是个非常容易被混淆的东西。

[参考文章](https://stackoverflow.com/questions/4934806/how-can-i-find-scripts-directory-with-python)。

需要`import os`和`import sys`
- 当前工作区: `os.getcwd()`，注意，这不是脚本的位置，而是命令行中的工作区位置。
比如当你在`~/A/`执行`~/B/`文件夹中的一个python代码，那么返回的是`~/A/`，因为命令行中的工作区在`~/A/`.
- 当前文件名：`sys.argv[0]`或`__file__`，注意，两个变量都不稳定。__file__这个默认变量在一些环境下是没有被定义的，sys.argv[0]有时是完整路径有时只是一个文件名，所以，慎用。最好都配合os.path的各种方法运用。
- 当前文件完整路径：`os.path.realpath(sys.argv[0])`
- 当前文件所在文件夹：`os.path.dirname(os.path.realpath(sys.argv[0]))`





# python调用命令行
参考[这篇文章](https://www.jianshu.com/p/5d999a668e79)

```python
import os

#只返回结果
os.system(command)

#返回结果与终端显示信息
with os.popen(command, mode) as f: 
    print f.read()

```





# Python代码之美
> 有时特别想摘抄一些别人漂亮的代码书写。在这里贴上吧。

### [`gh-issues-import.py`](https://github.com/IQAndreas/github-issues-import/blob/master/gh-issues-import.py)
代码整齐和常量名全大写
![image](https://user-images.githubusercontent.com/14041622/35791554-9d0f75d4-0a83-11e8-8110-cfd227a4f198.png)
分隔有序，不用注释也可以清晰表面之间分别
![image](https://user-images.githubusercontent.com/14041622/35791749-7734bc38-0a84-11e8-9143-5db51fa864c4.png)
简单函数和复杂函数的断行方式
![image](https://user-images.githubusercontent.com/14041622/35791839-dab7cb1a-0a84-11e8-9601-d6e18c8b6871.png)






# Python 读取JSON数据

```python
import json

him = json.loads( '{"title": "Jason", "content": "hello"}' )

print( him['title'] )
```
Out:
```
Jason
```





# Python中文解决方案 （简易）
翻了翻几年前研究Python中文编码的问题，原来如此复杂。。。。一时间全忘了。
为了避开这个理论上的难题，我直接开启了实验出真知的模式，试验出一个简单的方法。
简单来说如下：
1. 首先页头要有`# -*- coding: utf-8 -*-`的声明
2. 整个py文件中，只要任何一处设计字符串，都要认真处理
3. 所有获得的字符串，都要先进行`"字符串".decode('utf-8)`解码为某种原始编码。
4. 所有要发出的或写入文件的，都必须要进行`"字符串".encode('utf-8')`编码为统一码。





# 为什么是IPython?
python里面调试确实有点烦恼，尤其是在vim里，想要尝试一些简单的编码问题，实在是有点麻烦，不想到命令行模式一行一行执行，也不想再新建一个文件测试一个简单的功能。
而且就是不管这些，测试一个简单的功能如学习语法、测试编码、测试新学习的包等，在IDE里面测试，看不到每个部分的output效果（除非自己手动去命令行里复制或截屏），在命令行里测试，则没法轻松撤销前面的代码。。。。
所以这时候才想到好像前阵子看到youtube视频里别人用IPython，是那种又能轻松编辑又能为每部分显示output效果，还能在旁做markdown笔记的东西。
出于这个想法，搜到了这篇[知乎回答](https://www.zhihu.com/question/51467397)，看到了不少有意思的东西，感觉又展开了一个崭新的领域，python的视界豁然开朗。
[这篇文章](https://zhuanlan.zhihu.com/p/33654849)极好的解释了IPython的入门用法，相当酷！我怎么竟然这么久都不知道这种东西的存在？

### IPython和Jupyter的区别？
据说一开始IPython是作为`IPython shell`的存在，后来Jupyter融合了它，又把自己和IPython上独立出来，做成了网页版的`Jupyter Notebook`这样的东西。Jupyter强大的特性，加上和各种数据研究库的紧密结合，真让人不能忽视它的存在了。
IPython的安装方法，简单地`pip install ipython`即可。
但是，想到IPython本身一个shell，让我想起了我自己用的shell是`zsh`，让我把zsh切换到别的shell里面去，还真有点不喜欢。。这可能是个stylish issue吧。
所以，应该直接了当的安装jupyter，其中也会自动安装上`IPython shell`，作为其运行的Kernel。

## 安装Jupyter
只安装Jupyter本身的话，超简单：`pip install jupyter`。
不过根据官方文档，强烈建议安装Jupyter的`Anaconda`发行版，像大礼包一样的自动安装`python+Jupyter Notebook+一系列数据研究库`。
因为本来就是要研究机器学习等一系列数据研究的，所以Anaconda正合适。
这个我觉得再好不过了，所以直接跳到[`Anaconda`页面](https://www.anaconda.com/download)去看安装方法。
然后看到，Anaconda安装方法是不能简单`apt-get`或`brew`或`pip install`的，500M左右的大小，需要下载后启动图形安装工具或shell脚本安装（`.sh`文件本身就500M，而且安装分为Python 3和Python 2的两种方式。
![image](https://user-images.githubusercontent.com/14041622/35910000-25554b14-0c30-11e8-9102-3c61460c3b39.png)

## 启动Jupyter
安装好Anaconda后，就可以通过GUI应用启动了。但是这种方式不推荐，软件体积太大，而且还存在一些学习成本，麻烦。界面如下图：
![image](https://user-images.githubusercontent.com/14041622/35916826-b5514c48-0c46-11e8-9839-cf4ed9f333f4.png)

感觉用命令行启动更简单，在某个工作目录，输入：
```
jupyter notebook
```
这样就能以这个目录打开一个`http://localhost:8889/tree`的网页，一切都在这个网页里操作。

### iTerm2无法在命令行里启动Jupyter
总是报`command not found jupyter`错误，说没有这个命令。一开始还以为是zsh的问题，可是切换到bash也一样。
照着网上攻略在`.zshrc`里改也没用，在`.bash_profile`里改也没用。
然后发现，在Mac自带的Terminal.app中就可以正常打开，不需要改任何配置。
这才知道原来是iTerm2无法识别。于是在Terminal.app中用`which`命令查看jupyter命令的所在处，看到它位于`/Users/我的用户名/anaconda2/bin/jupyter`这个地方。
于是直接在`~/.zshrc`中加入alias：
```
alias jupyter="/Users/我的用户名/anaconda2/bin/jupyter"
```
重启iTerm2，好用！

但是，iTerm2中的bash还是不能访问，用同样的方法也不行。暂时没找到解决方法。






# Python `requests`库抓取网页出现乱码
> 练习抓取网页时遇到的，如果是简书等这些标准网站，正常抓取是没问题的。但是很多网页竟然怎么抓取都是所有中文都乱码。弄的我还以为是python代码本身的encoding问题。最后才追溯到原来是出现在源头requests库里面。

参考这两篇文章，[requests官方文档](http://docs.python-requests.org/zh_CN/latest/user/quickstart.html)， 和，[代码分析Python requests库中文编码问题](http://xiaorui.cc/2016/02/19/%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90python-requests%E5%BA%93%E4%B8%AD%E6%96%87%E7%BC%96%E7%A0%81%E9%97%AE%E9%A2%98/)，非常有参考性。

第二篇文章中看到，很多网页实际上并不都是`utf-8`的编码格式，还有很多是`ISO-8859-1`格式，如下图：
![image](https://user-images.githubusercontent.com/14041622/35913040-5fb39cc6-0c39-11e8-9cee-8dc8e7961918.png)
但是，其实不是网页本身的问题！我们查看网页本身的`headers`发现，他们的`charset`值是`utf-8`，但是为什么用`r.encoding()`得到的却是`ISO-8859-1`呢？文章中指出原来是requests的bug，而且常年不解决。所以就需要我们自己来想办法。
我们不能手动去检查每一个网页的编码啊，那样太麻烦了。
官方文档中出现了这么一小句话，非常重要，亲测有效：
![image](https://user-images.githubusercontent.com/14041622/35913251-0508ce9e-0c3a-11e8-8f76-188c026436ca.png)
虽然这句话不是为了处理网页的，但是`二进制`！沿着这个思路，又在官网看怎么将网页获取为二进制模式的：
![image](https://user-images.githubusercontent.com/14041622/35913331-3c097b96-0c3a-11e8-8bed-5a872e457116.png)
就是使用`r.content`获取。






# 关于解决Python乱码问题的终极解决方案 (TL;DR)
![image](https://user-images.githubusercontent.com/14041622/35929949-a242afbe-0c6b-11e8-8848-508c4e8124d1.png)

> 有个特别好玩的现象，当我们为了python编码头疼的时候，几乎搜索到所有的文章都会先发一通牢骚。然后在无可奈何地写解决思路（是解决思路不是方案）。这个问题真不是新手问题，即使是十几年python老手也经常头疼。中国外国都一样。看看这个python专家在[PyCon大会上用半个多小时讲解乱码的视频](https://www.youtube.com/watch?time_continue=1040&v=sgHbC6udIqc)就了解了，他自己都给自己的来回encoding, decoding, encoding, decoding说晕了，台下举手他都拒绝回答，可想而知这个问题复杂性。

我认为，几乎每个pythoner，都会有一段人生浪费在了编码上。可以说这个问题，是如果你不彻彻底底解决，就永远会崩溃的地步。翻看我曾经写的数篇文章就知道了：
- [对Python 2.x的通宵抱怨](https://github.com/solomonxie/solomonxie.github.io/issues/9)
- [Python中文字符的理解：str()、repr()、print ](https://github.com/solomonxie/solomonxie.github.io/issues/10)
- [Python里中文编码的理解：unicode、utf-8、gbk](https://github.com/solomonxie/solomonxie.github.io/issues/20)

牢骚结束，下面是我又一次用了两个整天才测试整理书写完成的ipython notebook笔记。`ipynb`格式的笔记源文件在这里，当然有可能会链接失效，有喜欢ipython的live coding笔记的且想要用这个笔记测试编码的，请联系我。

### 首先，需要先要了解python的`print大法`
如果python的print的特性都没有了解的话，希望你不要贸然尝试用print去调试测试乱码编码的问题。
这里的print厉害到让你不高兴的地步——它不管你塞过来的是什么格式什么编码，字符串数组对象什么的的都一口气全打印出来。
感觉好像很好，但其实是我们仔细研究编码问题的最大阻碍。
因为你塞给print一个unicode它能打出中文，塞一个utf-8或iso8895给它，也一样给你打印出原文。这样以来，你看着它出现原文后，就欣喜若狂产生了一种胜利的错觉。
所以我想在这里最先说清楚它：
#### 不要轻易在研究乱码的时候用print测试目标！
也不是说这种时候一点都不能用，而是说你可以print别的什么东西，但是如果想看清某个变量本质的话，千万不要用。
这个时候要用`print repr(字符串)` ,或者最好是在命令行或ipython里面测试，像这样：
![image](https://user-images.githubusercontent.com/14041622/35959122-2d49108a-0cdf-11e8-8a92-66872afc4782.png)

看出区别了吗？明确了这点，再来继续研究编码问题。

### 简单来说，先要记住，在Python2里字符串只有两大阵营：

## `unicode`和`str`

如果`type(字符串)`显示结果是`str`，其实指的是`bytes`字节码。
而其它各种我们所说的`utf-8`，`gb2312`等等也都是Unicode的不同实现方式。
这里不要去考虑那么复杂，只要先记住这两大阵营就行。

## `encoding`和`decoding`

绝对要记住的：
从`unicode`转换到`str`，这个叫`encoding`，编码。
从`str`转换到`unicode`，这个叫`decoding`，解码。
![image](https://user-images.githubusercontent.com/14041622/35937299-c7e99858-0c80-11e8-8c0d-aedfb723a2c1.png)
(图片引用自知乎相关某答案。)

来回记住这个问题，才能进入下一步！

然后来看个案例。
![image](https://user-images.githubusercontent.com/14041622/35928287-ca30e972-0c67-11e8-96d1-7d3a05e26e43.png)

> 通过上面两种格式的对比我们看到，str和unicode的各种区别。

那么，既然变量里面会出现两种不同的格式，如果我们把两种格式的字符串连在一起操作会发生什么呢？
如下：
![image](https://user-images.githubusercontent.com/14041622/35928324-dddbf200-0c67-11e8-96db-31061e6848eb.png)

### 看！著名的编码错误`UnicodeDecodeError: 'ascii' codec can't decode`就这样出现了！

以上是我们用`显性`字符串来比较两种格式字符串的区别。

但是，我们经常性处理python编码问题，都不是在这种`显性`的字符串上出现的，不是从网上爬取的就是从本地文件读取的，意思就是文件内容庞大，编码格式很难猜到是什么。
所以这里我们将问题再拆分为两部分讨论：本地文件和网络资源。

## 本地文件编码测试
首先在本地建立一个有中文的以`utf-8`格式保存的文本文件（实际上无论.txt还是.md等都无所谓，内容是一样的）。
内容只有'你好'。

### 然后我们来读取一下：
![image](https://user-images.githubusercontent.com/14041622/35928363-f0ffdb44-0c67-11e8-9b37-1cf8ebcb5ec0.png)

> 上面看到，从文件读取出来的，就是str格式的字符串。
那么如果要把str转化为unicode，就要解码，也就是decoding.

![image](https://user-images.githubusercontent.com/14041622/35928391-017b7d0c-0c68-11e8-8a73-eed6d071fc56.png)

### 这种时候实际上是最迷糊也最容易造成之后错误的，就是分不清该编码还是该解码。

> 所以上面提到，必须要记住这两个区别。
那么如果现在我搞反了怎么办？就会再次出现下面错误：

![image](https://user-images.githubusercontent.com/14041622/35928408-10b50180-0c68-11e8-8a41-9d4d97a3be66.png)

### 话说回来，我们该怎么统一他们呢？
> 为了避免两种格式的字符串在一起乱搞，统一他们是必须的。但是以哪一种为统一的呢，unicode还是bytes?

网上各种文章统一口径，要求代码中出现所有的变量都统一为unicode。
可是我在实践和测试中都越来越发现：这种做法真的不那么可靠，甚至我怀疑有可能我们碰到那么多的问题，都是由它搅乱引起的。

#### 下面我们来看看做常用的环境下字符串都是什么格式

![image](https://user-images.githubusercontent.com/14041622/35928691-b8c8ea1c-0c68-11e8-952d-97c8c205ae79.png)

> 这样就明白了：除了r.text返回的内容外，其它几乎都是使用str格式，也就是bytes字节码码。所以我们只要转化requests相关的内容就行！

实际上，requests返回的response中, 除了用`.text`获取内容，我们还可以用`.content`获取同样的内容，只不过是bytes格式。

那就正和我们意，不用再去转化每一个地方的字符串，而只要盯紧这一个地方就足够了。

### 为什么我们不能把所有字符串变量统一为unicode呢？

先提醒下，变成unicode的过程，叫`decoding`。不要记错。
像`.text`经常把`ISO8859`等猜不到也检测不到编码(机率很低)的字符串扔过来，如果遇到的话，是很麻烦的。
`decoding`有两种方法：
```
unicode(b'你好‘）
b'你好'.decode('utf-8')
```

这里因为不知道来源的编码，所以必须用`unicode()`来解码，而不能用`.decode('utf-8')`，因为显然你不能乱写解码名称，如果来源果真是（很大几率是）`ISO8859`等方式，那么错误的解码肯定会产生乱码，或者直接程序报错。切记！

所以这里只能用`unicode()`解码。如下例：

![image](https://user-images.githubusercontent.com/14041622/35928475-387899f2-0c68-11e8-9821-3f31939c7742.png)

##  结论：一定记住，全文都统一用`str`格式字符串
### 只要盯紧requests、json等这种经常处理外来资源的库就好了。
只要控制好外来源的字符串，统一为`str`，其它一切都好说！

> 实际上，我发现遇到的绝大多数编码问题，实际上不是python原生方法导致的，而是这些外来库所引起的！因为每个模块都会有自己的一套处理编码的方式，你还真不知道它是采用哪个。就像JSON的dumps()一样埋着大坑等着我们。所以真正应该盯紧的就是这些库了。


下面是一个从获取网络资源（含中文且被requests认为编码是ISO8850的网页）到本地操作且存储到本地文件的完整测试。
```python
import requests

r = requests.get('http://pycoders-weekly-chinese.readthedocs.io/en/latest/issue5/unipain.html')

# write a webpage to local file
with open('test.html', 'w') as f:
    f.write( r.content )

# read from a local html file
with open('test.html', 'r') as f:
    ss = f.read()
```
大功告成！效果如下：

![image](https://user-images.githubusercontent.com/14041622/35929410-69cf7e42-0c6a-11e8-915d-f020a729bbb4.png)

### 再也不用纠结、检查每一个变量、写一大堆嵌套转化方法了！注意，只要盯紧各种外来模块和库的文字处理就够了。

> 另外，关于JSON的乱码问题，又是一个新的较长篇章。我会单分一篇，请到我的专栏里找。





# Python操作JSON出现乱码的解决方案
> 其实刚刚写过一整篇Python编码问题的解决方案，由于JSON又是一种特殊案例（与库相关，与语言本身无关）所以就单独提出来说。


## 我们来看一个从网上获取json并又存到本地文件的例子
```python
import requests,json

r = requests.get('https://api.github.com/repos/solomonxie/\
solomonxie.github.io/issues/25/comments')

# 获取到我的github中某条issue的所有评论，形式为<JSON格式的字符串>
comments = json.loads( r.content )

# 取某一条评论查看内容（中文）
cc = comments[0]['body'][0:10] # 取出的内容是'## 配置：先从配置'
```
然后来测试下变量cc：
![image](https://user-images.githubusercontent.com/14041622/35958210-88aad5ee-0cda-11e8-8192-08a8da696a31.png)

### 好，到这里先停一下！
JSON的读取到目前为止，都是正常的：JSON Object对象给出的值都是unicode，没有被莫名转义，也没有报错误。
> 但是，unicode格式，意味着它和str格式不兼容！
这时，害羞的大姑娘Unicode刚出炉，你不能在这个时候让它和Str操作在一起！
报错也往往就在这种疏于防备的时候！

比如你看：

![image](https://user-images.githubusercontent.com/14041622/35958360-59681c8c-0cdb-11e8-9a83-c825e4a9eb8b.png)

上面打印了三条Unicode和Str的结合，
前两条分别是以Str格式的结合，以Unicode格式的结合。
但是第三条，把两个不同格式的字符串结合，就出错了。

对不起，这里不是Javascript，变量不可以任意交合。Python对变量和编码都是极其谨慎的。

所以明白了这点，我们再继续。

### 上面获得了JSON Object对象，那么再来试试将`JSON对象`整体存到文本文件中。
如果要存到本地文件，那么就必须把Object对象转换为Str格式的字符串。
json库自带.dumps()函数可以进行转化。
但是这里问题出现了！我们来小试一下：
![image](https://user-images.githubusercontent.com/14041622/35958250-b7b04900-0cda-11e8-860b-bc1494274be5.png)
> 竟然连`print大法`都不能把`json.dumps()`返回的内容正确打印出来。经过各种测试和查看官网对于此函数的文档，发现：

### 原来`json.dumps()`是默认所有非ascii码强制转化为代号（而非汉字）的，于`repr()`效果等同！
[官方文档](https://docs.python.org/2/library/json.html#encoders-and-decoders)里有说明，`json.dumps()`里面有个`ensure_ascii`参数，默认为True。
意思就是默认把所有非ascii字码用`\`强制转化。所以，为了关闭这个功能，我们必须把它设为`False`.
下面是个小测试：
![image](https://user-images.githubusercontent.com/14041622/35958259-c42808e4-0cda-11e8-87ca-dc16e0816567.png)

### 这样一来JSON在Python里的编码问题就解决了：须用`json.dumps(obj,  ensure_ascii=False)`来转化为字符串

下面是完整的代码测试：
```python
# @网络资源到本地存储真实测试
import requests,json

r = requests.get('https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/25/comments')

# 获取到我的github中某条issue的所有评论，形式为<JSON格式的字符串>
comments = json.loads( r.content )

outgoing = json.dumps( comments, ensure_ascii=False )

with open('test.txt', 'w') as f:
    f.write(outgoing.encode('utf-8'))
with open('test.txt', 'r') as f:
    read = f.read()
    
print read[0:20], type(read)
```
来看结果：
![image](https://user-images.githubusercontent.com/14041622/35958296-f90e1260-0cda-11e8-8aed-2a320a9ac6f1.png)

## 大功告成！





# 更多Python编码的小细节

## 数组`.join()`合并
数组中必须所有的元素都是字符串，且都是统一的编码才能合并，否则报错。统一后，如果全是unicode，那么返回的字符串就是unicode；如果元素全是str，那么返回的就是str。
![image](https://user-images.githubusercontent.com/14041622/35965010-6c01a23c-0cf4-11e8-81ce-9340217d9553.png)








# python将某个目录打包为`zip`文件
比较古老的方法是用`zipfile`库创建zip包，但是要写各种循环迭代需要很多行代码。
还有另一种[python自带库`shutil`](http://python.usyiyi.cn/translate/python_278/library/shutil.html),可以一句话打包为zip文件。
```
import shutil
shutil.make_archive(base_name, format, root_dir, base_dir)
```
很快就打包好了！
唯一注意的是，怎样把它安装自己想象的结构打包。
- base_name，是加上完整路径（不能缩写）的文件或文件夹名
- format一般是zip，其它tar之类也行
- root_dir是要压缩的目录或文件
- base_dir是压缩包里的文件层级。如你写`a/b/c`，这样所有文件都会塞到最底层的c文件夹中。





# Python 日期和时间
```
from datetime import date
print str( date.today() )
```





# Python调试工具`pdb` —— Python Debuger
[参考文章1](https://zhuanlan.zhihu.com/p/25942045)。
[参考文章2](https://docs.python.org/2/library/pdb.html)
![image](https://user-images.githubusercontent.com/14041622/35992333-f5e0e544-0d44-11e8-868c-3722bbb24903.png)

![image](https://user-images.githubusercontent.com/14041622/35991850-77a2bb90-0d43-11e8-9aad-a46cb9869136.png)






# 用requests报错`requests.exceptions.SSLError`
![image](https://user-images.githubusercontent.com/14041622/35994940-df8d7214-0d4c-11e8-95fa-b4824ddde4d8.png)
明明没有改代码，突然就报这种错误。
调查发现，原来是被服务器拒了。可能是今天来回调试，多次访问同一个地址，就被屏蔽了。
但是，同样是没有设置请求Headers的客户端postman和insomnia就还能正常访问，不知道为什么。





# Python操作Git库 `GitPython`
[参考文章](http://note.qidong.name/2018/01/gitpython/)
[参考文章](http://www.cnblogs.com/baiyangcao/p/gitpython.html)
[复杂点的参考](https://my.oschina.net/hopeMan/blog/141221)

试了一圈发现，git库的用法设置非常符合原生git命令，只不过之间加了个`.`而已。
比如原本命令行里是`git add .`，这里就是`repo.git.add('.')`，
原本是`git commit -m "信息"`，这里就是`repo.git.commit(m='信息')`
可以说减少了很多学习时间，基本上我很多都是没参考文档自己猜出来的也能用。

```
sudo pip install gitpython
```
库安装好后可以直接在python中用了。

### 创建、识别、克隆仓库
文件夹地址可以是全路径，也可以是`.`当前文件夹、`../`上级文件夹等用法。
```
# 在文件夹里新建一个仓库，如果已存在git仓库也不报错不覆盖没问题
repo = git.Repo.init(path='文件夹地址')

# 选择已有仓库
repo = git.Repo( '仓库地址' )

# 克隆仓库
repo = git.Repo.clone_from(url='git@github.com:USER/REPO.git', to_path='../new')
```
### 常用语句：
```python
# 查看repo状态
print repo.git.status()   # 返回通常的status几句信息
print repo.is_dirty()    # 返回是否有改动（包括未add和未commit的）

# 添加文件 可以是单个文件名，也可以是`[ ]`数组，还可以是`.`代表全部
print repo.git.add( '文件名' )

# commit提交
print repo.git.commit( m='提交信息' )
```

### 远程交互操作
```python
# 创建remote：
remote = repo.create_remote(name='gitlab', url='git@gitlab.com:USER/REPO.git')

# 远程交互：
remote = repo.remote()
remote.fetch()
remote.pull()
remote.push()
```

### 实验效果
```python
 # 原意是返回工作区是否改变的状态
# 但是测试发现，工作区有变动它返回False，没变动却返回True
print repo.is_dirty()
```

### 生成tar压缩包
```python
# 压缩到 tar 文件
with open('repo.tar', 'wb') as fp:
    repo.archive(fp)
```





# Pip 显示模块包的安装路径
``` 
pip show <package name>
```





# Python 删除某文件夹
[参考文章](https://askubuntu.com/questions/555318/delete-all-files-except-files-with-the-extension-pdf-in-a-directory/555326)
- os.remove() will remove a file
- os.rmdir() will remove an empty directory
- [shutil.rmtree()](https://docs.python.org/3/library/shutil.html#shutil.rmtree) will delete a directory and all its contents

```python
# 删除某个目录及里面所有内容，第二个参数为True时忽略所有错误中断
shutil.rmtree('<path>', True)
```








# Python 异常捕获
常用配置是这样的：
```
try:
    do_something()
except BaseException as e:
    print 'Failed to do something: ' + str(e)
```






# Python 睡眠
[参考文章](https://www.pythoncentral.io/pythons-time-sleep-pause-wait-sleep-stop-your-code/)

```python
import time
 
# Wait for 5 seconds
time.sleep(5)
 
# Wait for 300 milliseconds
# .3 can also be used
time.sleep(.300)
```





# Jupyter Notebook IPython无法识别Module问题
因为Jupyter notebook的python不是系统里的python， 而是运行在`/Users/solomonxie/anaconda2/bin/python`这里的。同时还有其他很多位置、kernel等等问题非常复杂，网上目前还很难找到比较简单的解决方案。
唯一看到的是[这篇文章](https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/)，讲到很不一样的思路，即用conda还是pip来安装module的分别。





# Python集合的操作
> 有时候在对比两个数组，如果运用上集合的话就会相当精妙。

### 基本操作
[参考文章](http://blog.csdn.net/business122/article/details/7541486)
```python
s = set([3,5,9,10])
t = set([1,2,3,4,5,6,7,8,9,10])

# 基本运算
a = t | s          # t 和 s的并集  
b = t & s          # t 和 s的交集  
c = t – s          # 求差集（项在t中，但不在s中）  
d = t ^ s          # 对称差集（项在t或s中，但不会同时出现在二者中） 

# 基本操作：  
t.add('x')            # 添加一项  
s.update([10,37,42])  # 添加多项  
t.remove('H')     #删除一项
```
以下来自[官方参考](https://docs.python.org/2/library/sets.html)：

![image](https://user-images.githubusercontent.com/14041622/36139421-626ac50e-10d8-11e8-8f40-eb63c095956e.png)

![image](https://user-images.githubusercontent.com/14041622/36139390-467c0b3c-10d8-11e8-95e4-072b164ac9c3.png)






# python 日志记录学习
> 更新：`Python Logging`原来真的远比我想象的要复杂很多很多，学习路线堪比git。但是又绕不过去，alternatives又少，所以必须要予以重视，踏踏实实认认真真的来好好学学才行。

> 简单脚本还好，print足够。但是稍微复杂点，哪怕是三四个文件加起来两三百行代码，调试也开始变复杂起来了。再加上如果是后台长期运行的那种脚本，运行信息的调查更是复杂起来。一开始我还在各种查`crontab`的日志查看，或者是`python后台运行查看`，或者是`python stdout的获取`等等，全都找错了方向。真正的解决方案在于正确的logging。记录好了的话，我不需要去找python的控制台输出`stdout`，也不需要找`crontab`的日志，只需要查看log文件即可。下面是python的logging学习记录。


参考文章：[Good logging practice in Python](https://fangpenlin.com/posts/2012/08/26/good-logging-practice-in-python/)，[优雅地记录Python程序日志](http://zmister.com/archives/213.html) ，[进阶配置](http://huangming.work/2016-05-29-python-log.html)

### 最简单的日志输出（无文件记录）
```python
import logging
 
logging.error("出现了错误")
logging.info("打印信息")
logging.warning("警告信息")
```





# 定期执行Python脚本
目前知道的有两种方法：python自带的`time.sleep()`定时器循环执行某段代码 和 linux系统的`crontab`命令定期执行某个脚本

- `time.sleep()`方法，这个方法是执行脚本一次，然后内在代码在`while`循环中定期迭代。这种的问题在于，一旦将程序切换到后台，或者部署在服务器上断开ssh连接时，脚本就停止了。
- `crontab`方法，是定期执行整个脚本。这个能够满足一般要求，唯一问题是它不会输出任何脚本的stdout，而是默默的执行。所以要想做这个，又能看到进程，需要用比较复杂的方法来配合执行。





# Python执行脚本将输出重定向时编码错误
> 原本以为python内部的编码问题解决了，但是用linux命令将标准输出重定向时没想到又遇到了亲切的编码问题。
![image](https://user-images.githubusercontent.com/14041622/36322055-f02f0200-1386-11e8-8071-d394cca60f68.png)

根据[文章](http://www.708luo.com/posts/2014/06/python-print-encode-error/) 和 [文章](https://mozillazg.com/2014/01/python-fix-shell-python-program-redirect-to-file-raise-unicodedecodeerror)的解释，是因为linux的重定向命令并不知道python文件的输出编码而默认使用了ascii，所以当输出有超出128的字都会报错。
解决方法很简单：

在执行python的命令前加上`env PYTHONIOENCODING=utf-8`，如：
```shell
env PYTHONIOENCODING=utf-8 python ~/hello.py >> log.txt
```

还可以分开写：
```
$ export PYTHONIOENCODING=utf8
$ python hello.py  > hello.txt
```

这里还有一些相关的[stackoverflow回答](https://stackoverflow.com/questions/3828723/why-should-we-not-use-sys-setdefaultencodingutf-8-in-a-py-script)。

## 这还是不能输出所有内容
因为linux输出重定向的道理（在刚刚写的Linux学习的篇章里有专门说明），光是编码还不行，会发现还有很多内容并没有转向到文件里，而还是显示在屏幕上了。
其实我们上面写的转向语句，只是把显示在屏幕上的`stdout`标准输出转向了日志文件，可是还有`stderr`标准错误没有转向到日志文件，所以才显示到了显示屏里。
虽然看上去很多内容看起来并不是错误，比如`git push`的正常返回，好像和`stderr`标准错误没什么关系，可是它们本质上是通过`stderr`输出到屏幕的，只是我们不知道而已。
所以这时候，
应该把标准错误合流到标准输出里，一起转向。
在命令的结尾加上`2>&1`，让2转向1，意思就是让标准错误转向至标准输出。其中`>`代表`Redirect to`，`&`没意义只是用来告诉系统后面的1是代表输出设置，而不是文件名。

用上面的例子，这里应该这样写：
```shell
env PYTHONIOENCODING=utf-8 python ~/hello.py >> log.txt 2>&1
```

然后，哒哒！屏幕上不会显示任何内容了！也就是说所有的东西都转向了log.txt文件里保存。


