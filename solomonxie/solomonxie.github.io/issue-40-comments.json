[{"url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/comments/367909998","html_url":"https://github.com/solomonxie/solomonxie.github.io/issues/40#issuecomment-367909998","issue_url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/40","id":367909998,"user":{"login":"solomonxie","id":14041622,"avatar_url":"https://avatars2.githubusercontent.com/u/14041622?v=4","gravatar_id":"","url":"https://api.github.com/users/solomonxie","html_url":"https://github.com/solomonxie","followers_url":"https://api.github.com/users/solomonxie/followers","following_url":"https://api.github.com/users/solomonxie/following{/other_user}","gists_url":"https://api.github.com/users/solomonxie/gists{/gist_id}","starred_url":"https://api.github.com/users/solomonxie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/solomonxie/subscriptions","organizations_url":"https://api.github.com/users/solomonxie/orgs","repos_url":"https://api.github.com/users/solomonxie/repos","events_url":"https://api.github.com/users/solomonxie/events{/privacy}","received_events_url":"https://api.github.com/users/solomonxie/received_events","type":"User","site_admin":false},"created_at":"2018-02-23T04:58:01Z","updated_at":"2018-05-01T16:28:17Z","author_association":"OWNER","body":"## TL;DR. Archived link: [Vector section notes of Essence Linear Algebra](https://github.com/solomonxie/solomonxie.github.io/issues/21#issuecomment-379985082)\r\n\r\n## TL;DR Archived link: [MIT OCW Linear Algebra courses list & compare](https://github.com/solomonxie/solomonxie.github.io/issues/21#issuecomment-380001327)."},{"url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/comments/370467603","html_url":"https://github.com/solomonxie/solomonxie.github.io/issues/40#issuecomment-370467603","issue_url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/40","id":370467603,"user":{"login":"solomonxie","id":14041622,"avatar_url":"https://avatars2.githubusercontent.com/u/14041622?v=4","gravatar_id":"","url":"https://api.github.com/users/solomonxie","html_url":"https://github.com/solomonxie","followers_url":"https://api.github.com/users/solomonxie/followers","following_url":"https://api.github.com/users/solomonxie/following{/other_user}","gists_url":"https://api.github.com/users/solomonxie/gists{/gist_id}","starred_url":"https://api.github.com/users/solomonxie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/solomonxie/subscriptions","organizations_url":"https://api.github.com/users/solomonxie/orgs","repos_url":"https://api.github.com/users/solomonxie/repos","events_url":"https://api.github.com/users/solomonxie/events{/privacy}","received_events_url":"https://api.github.com/users/solomonxie/received_events","type":"User","site_admin":false},"created_at":"2018-03-05T16:01:47Z","updated_at":"2018-05-01T17:01:33Z","author_association":"OWNER","body":"# `What is Linear Algebra`\r\n\r\nLinear algebra, Matrix algebra, same thing.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39481781-25f6f346-4d9f-11e8-988e-0c1623e6edca.png)\r\n\r\n## Terms sheet\r\n![image](https://user-images.githubusercontent.com/14041622/39066642-51cd6ce2-4508-11e8-9863-4cc7f0497983.png)\r\n\r\n\r\n## Consistent & Inconsistant\r\n> If there IS solution or solutions to a `Linear system`, then it's consistent. Otherwise, it's Inconsistent.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39482015-084f14d0-4da0-11e8-8e0a-5cdec4232732.png)\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39482161-86ec503c-4da0-11e8-9e4e-51207852f3c4.png)\r\n\r\n"},{"url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/comments/381383946","html_url":"https://github.com/solomonxie/solomonxie.github.io/issues/40#issuecomment-381383946","issue_url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/40","id":381383946,"user":{"login":"solomonxie","id":14041622,"avatar_url":"https://avatars2.githubusercontent.com/u/14041622?v=4","gravatar_id":"","url":"https://api.github.com/users/solomonxie","html_url":"https://github.com/solomonxie","followers_url":"https://api.github.com/users/solomonxie/followers","following_url":"https://api.github.com/users/solomonxie/following{/other_user}","gists_url":"https://api.github.com/users/solomonxie/gists{/gist_id}","starred_url":"https://api.github.com/users/solomonxie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/solomonxie/subscriptions","organizations_url":"https://api.github.com/users/solomonxie/orgs","repos_url":"https://api.github.com/users/solomonxie/repos","events_url":"https://api.github.com/users/solomonxie/events{/privacy}","received_events_url":"https://api.github.com/users/solomonxie/received_events","type":"User","site_admin":false},"created_at":"2018-04-15T06:37:44Z","updated_at":"2018-05-04T16:23:05Z","author_association":"OWNER","body":"# MIT OCW 18.06 SC Unit 1.1 The geometry of linear equations\r\n\r\n[Refer to the review pdf.](https://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/ax-b-and-the-four-subspaces/the-geometry-of-linear-equations/MIT18_06SCF11_Ses1.1sum.pdf)\r\n\r\nLecture video timeline | Links\r\n-- | --\r\nLecture | [0:00](https://www.youtube.com/watch?v=ZK3O402wf1c&t=0s&index=1&list=PLE7DDD91010BC51F8)\r\nMatrix picture | [2:47](https://youtu.be/ZK3O402wf1c?t=2m47s)\r\nRow picture | [3:41](https://youtu.be/ZK3O402wf1c?t=3m41s)\r\nColumn picture | [8:41](https://youtu.be/ZK3O402wf1c?t=8m41s)\r\nMatrix picture in 3D | [15:26](https://youtu.be/ZK3O402wf1c?t=15m26s)\r\nRow picture in 3D: intersects of planes | [17:33](https://youtu.be/ZK3O402wf1c?t=17m33s)\r\nColumn picture in 3D | [23:11](https://youtu.be/ZK3O402wf1c?t=23m11s)\r\nPermutation Matrix | [36:42](https://youtu.be/QVKj3LADCnA?t=36m42s)\r\n\r\n> \"The fundamental problem of linear algebra is to solve n linear equations in `n` unknowns.\"\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/38993221-93ad3a46-4415-11e8-8d2f-c3c88abac23b.png)\r\n\r\nWe view this problem in three ways:\r\n- `Row picture`: Each row is an equation, and we could draw out each line equation on the graph.\r\n- **`Column picture`**: Rewrite equations in the form below, and each column is a vector, and we could each vector (with scalar) on the graph.\r\n- `Matrix picture`: Rewrite equations into `Coefficient Matrix form`, and see the geometric meaning of a matrix and vector.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39082877-d8f0be02-458c-11e8-9da5-fdcc95edeefc.png)\r\n\r\n\r\n"},{"url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/comments/383020020","html_url":"https://github.com/solomonxie/solomonxie.github.io/issues/40#issuecomment-383020020","issue_url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/40","id":383020020,"user":{"login":"solomonxie","id":14041622,"avatar_url":"https://avatars2.githubusercontent.com/u/14041622?v=4","gravatar_id":"","url":"https://api.github.com/users/solomonxie","html_url":"https://github.com/solomonxie","followers_url":"https://api.github.com/users/solomonxie/followers","following_url":"https://api.github.com/users/solomonxie/following{/other_user}","gists_url":"https://api.github.com/users/solomonxie/gists{/gist_id}","starred_url":"https://api.github.com/users/solomonxie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/solomonxie/subscriptions","organizations_url":"https://api.github.com/users/solomonxie/orgs","repos_url":"https://api.github.com/users/solomonxie/repos","events_url":"https://api.github.com/users/solomonxie/events{/privacy}","received_events_url":"https://api.github.com/users/solomonxie/received_events","type":"User","site_admin":false},"created_at":"2018-04-20T08:14:03Z","updated_at":"2018-05-02T14:16:41Z","author_association":"OWNER","body":"# `Matrices Elimination`\r\n> `Matrices elimination` (or `solving system of linear equations`) is the very first and fundamental skill throughout Linear Algebra. It's probably the first lesson of all sorts of courses.\r\n\r\n## Terminology\r\nBefore learning `solving systems of linear equations`, you really need to get familiar with all the core terminologies involved, otherwise it can be very hard to move on to next stage.\r\nAnd in this case, the best way to learn that is through Wikipedia.\r\n\r\nJFR, the core terms are: `Gaussian elimination`, `Gauss-Jordan elimination`, `Augmented Matrix`, `Elementary Row Operations`, `Elementary matrix`, `Row Echelon Form (REF)`, `Reduced Row Echelon Form (RREF)`, `Triangular Form`.\r\n\r\n### [`Gaussian elimination`](https://en.wikipedia.org/wiki/Gaussian_elimination)\r\n> It's a `Row reduction algorithm` to solve System of linear equations.\r\n\r\n[Refer to simple wiki: Gaussian elimination](https://simple.wikipedia.org/wiki/Gaussian_elimination)\r\n[Example: showme.com](http://www.showme.com/sh/?h=3fjkVEW)\r\n\r\nTo perform `Gaussian elimination`, the `coefficients of the terms in the system of linear equations` are used to create a type of matrix called an `augmented matrix`. \r\nThen, `elementary row operations` are used to **simplify** the matrix. \r\nThe **goal** of Gaussian elimination is to get the matrix in `row-echelon form`. \r\nIf a matrix is in `row-echelon form`, which is also called `Triangular Form`.\r\nSome definitions of Gaussian elimination say that the matrix result has to be in `reduced row-echelon form`. \r\n**Gaussian elimination that creates a reduced row-echelon matrix result is sometimes called `Gauss-Jordan elimination`.**\r\n\r\nTo be simpler, here is the structure:\r\n- Algorithm: `Gaussian Elimination`\r\n    - Step 1: Rewrite system to a `Augmented Matrix`.\r\n    - Step 2: Simplify matrix with `Elementary row operations`.\r\n    - Result:\r\n        - `Row Echelon Form` or\r\n        - `Reduced Echelon Form`\r\n\r\nAnd if we make the result only in `RREF`, so the name of the algorithm could also be called:\r\n- Algorithm: `Gauss-Jordan Elimination`\r\n    - Step 1: Rewrite system to a `Augmented Matrix`.\r\n    - Step 2: Simplify matrix with `Elementary row operations`.\r\n    - Result: Only in `Reduced Echelon Form`\r\n\r\n### `Elementary Row Operations`\r\nElementary row operations are used to **simplify the matrix**. \r\n\r\nThe three types of row operations used are:\r\n- Type 1: **Switching** one row with another **row**.\r\n- Type 2: **Multiplying** a row by a non-zero **number**.\r\n- Type 3: **Adding** a row from another **row**. (!Note: you can only **ADD** them but not **subtract**, but you can **ADD** a negative)\r\n\r\nConfusing operation: See where the `negative sign` was put:\r\n![image](https://user-images.githubusercontent.com/14041622/39507688-b0f759aa-4e11-11e8-89b3-69846f64a53a.png)\r\n\r\n\r\n### Example\r\nSuppose the goal is to find the solution for the linear system below:\r\n![image](https://user-images.githubusercontent.com/14041622/39080182-31be1c9a-455c-11e8-927e-773f3788b77a.png)\r\n\r\nFirst we need to turn it into `Augmented Matrix` form:\r\n![image](https://user-images.githubusercontent.com/14041622/39080192-5804ace8-455c-11e8-96ec-57c0d884a69b.png)\r\n\r\nThen we apply `Elementary Row Operations`, and result in `Row Echelon Form`:\r\n![image](https://user-images.githubusercontent.com/14041622/39080203-a26b890a-455c-11e8-9f41-50c66079b22e.png)\r\n\r\nAt the end, if we'd like, we can further on apply some row operations to get the matrix in `Reduced Row Echelon Form`:\r\n![image](https://user-images.githubusercontent.com/14041622/39080275-2846e60a-455d-11e8-83c5-53b84fd5b45a.png)\r\nReading this matrix tells us that the solutions for this system of equations occur when x = 2, y = 3, and z = -1.\r\n\r\n### `Row Echelon Form vs. Reduced Row Echelon Form`\r\n[Refer to this lecture video: REF & RREF](https://www.youtube.com/watch?v=W01H0LcVUdQ&index=10&list=PLHXZ9OQGMqxfUl0tcqPNTJsb7R6BqSLo6).\r\n\r\nIt doesn't really matter it is a `Square Matrix` or not, there could be a `Diagonal` or `Main diagonal`, or you can't draw a diagonal at all. \r\nThe only thing matters is **WHAT ARE ABOVE 1 AND WHAT ARE BELOW 1.**\r\n\r\n- REF: For each column, all numbers **below** 1 MUST BE 0. Doesn't matter what numbers are above 1.\r\n- RREF: For each column, all numbers both **above & below** 1 MUST BE 0. We don't care about it if there's no 1 in the column.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39506655-9e283416-4e0c-11e8-9e58-1df4f85c25e6.png)\r\n\r\n## `Augmented Matrix`\r\n> Means we put another column into the matrix, which represents the **Right side** of the system of equations, numbers of right of the `=` sign.\r\n\r\nWhen we apply elimination to `Linear equations`, we operate both sides at the same time. But for computer programmes, it often apply to **Left side**, and remember the operations, a.g. multiply a number or add equations together, when the left side finished then apply the same operations to the right side.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39471215-829b2d90-4d74-11e8-97b1-7ce730e92e86.png)\r\n\r\nIf a given Matrix was told it's an `Augmented Matrix`, so we have to assume that the **Last Column** is **The Solution Column**.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39482311-20236e3e-4da1-11e8-859e-6954b2d33f4a.png)\r\n\r\n## `Equivalent systems & Equivalent Matrices`\r\n\r\n- Equivalent systems: Linear systems with the SAME SOLUTION SET.\r\n![image](https://user-images.githubusercontent.com/14041622/39482863-30ad3ee0-4da3-11e8-9314-8e6c9010690e.png)\r\n- Equivalent matrices: Two matrices where One Matrix **can be turned** into the other matrix by some `elementary row operations`.\r\n![image](https://user-images.githubusercontent.com/14041622/39482947-735664c4-4da3-11e8-8d4b-fc1b233adc87.png)\r\n\r\n## `Pivot`\r\n> Or called the `Cursor`, or `Basic`, or `Basic variable`.\r\n\r\n[Refer to this video from mathispower4u.](http://youtu.be/HFbBclH99d0)\r\n\r\nIt means the value that represents the `unknown variable`  in each column. There's no `pivot` in a column if you can't get a 1 in that column.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39506959-5ef42898-4e0e-11e8-89e0-8002688d81fb.png)\r\n\r\n### `Free variables`\r\nIf there's no pivot in a column, that means this `unknown variable` of the column can be **any number**, so we call it a `free variable`.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39507131-27751b7e-4e0f-11e8-9761-cef7ee48cd64.png)\r\n\r\n### `Pivot columns`\r\n\r\nThe `pivots` are found after `Row Reduction`, and then **go back** to the Original Matrix, the columns **WITH** pivots are called `pivot columns`.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39507277-ce962f42-4e0f-11e8-8638-917697b3a341.png)\r\n\r\n### `Back Substitution`\r\nIt's simple: When you solve out one `unknown variable` in the Linear System, you put the value back to other equations. We call this process as `Back Substitution`.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39522421-b93a512a-4e44-11e8-970c-b965fdee3808.png)\r\n"},{"url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/comments/385990238","html_url":"https://github.com/solomonxie/solomonxie.github.io/issues/40#issuecomment-385990238","issue_url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/40","id":385990238,"user":{"login":"solomonxie","id":14041622,"avatar_url":"https://avatars2.githubusercontent.com/u/14041622?v=4","gravatar_id":"","url":"https://api.github.com/users/solomonxie","html_url":"https://github.com/solomonxie","followers_url":"https://api.github.com/users/solomonxie/followers","following_url":"https://api.github.com/users/solomonxie/following{/other_user}","gists_url":"https://api.github.com/users/solomonxie/gists{/gist_id}","starred_url":"https://api.github.com/users/solomonxie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/solomonxie/subscriptions","organizations_url":"https://api.github.com/users/solomonxie/orgs","repos_url":"https://api.github.com/users/solomonxie/repos","events_url":"https://api.github.com/users/solomonxie/events{/privacy}","received_events_url":"https://api.github.com/users/solomonxie/received_events","type":"User","site_admin":false},"created_at":"2018-05-02T14:08:29Z","updated_at":"2018-05-02T14:08:29Z","author_association":"OWNER","body":"![image](https://user-images.githubusercontent.com/14041622/39527938-55f55a72-4e55-11e8-9f4e-d5ca9a984596.png)\r\n"},{"url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/comments/386033645","html_url":"https://github.com/solomonxie/solomonxie.github.io/issues/40#issuecomment-386033645","issue_url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/40","id":386033645,"user":{"login":"solomonxie","id":14041622,"avatar_url":"https://avatars2.githubusercontent.com/u/14041622?v=4","gravatar_id":"","url":"https://api.github.com/users/solomonxie","html_url":"https://github.com/solomonxie","followers_url":"https://api.github.com/users/solomonxie/followers","following_url":"https://api.github.com/users/solomonxie/following{/other_user}","gists_url":"https://api.github.com/users/solomonxie/gists{/gist_id}","starred_url":"https://api.github.com/users/solomonxie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/solomonxie/subscriptions","organizations_url":"https://api.github.com/users/solomonxie/orgs","repos_url":"https://api.github.com/users/solomonxie/repos","events_url":"https://api.github.com/users/solomonxie/events{/privacy}","received_events_url":"https://api.github.com/users/solomonxie/received_events","type":"User","site_admin":false},"created_at":"2018-05-02T16:13:17Z","updated_at":"2018-05-08T07:00:13Z","author_association":"OWNER","body":"# `Matrix multiplication`\r\n\r\n[Refer to this video by mathispower4u](https://www.youtube.com/watch?v=zAjUyPe-4mI&feature=youtu.be)\r\n\r\nPractice:\r\n- [ ] [Khan academy (simple)](https://www.khanacademy.org/math/precalculus/precalc-matrices/multiplying-matrices-by-matrices/e/multiplying_a_matrix_by_a_matrix)\r\n- [ ] [Symbolab (simple/advanced)](https://www.symbolab.com/practice/matrices-practice#area=main&subtopic=Multiply&isTour=false)\r\n- [ ] [Wolfram (beginner/Intermediate/Advanced)](https://www.wolframalpha.com/problem-generator/quiz/?category=Linear%20algebra&topic=MultiplyNMatrices)\r\n- [ ] [UOS](http://www.maths.usyd.edu.au/u/UG/JM/MATH1002/Quizzes/quiz7.html)\r\n\r\nA fairly simple way to remember how to do `matrix multiplication`:\r\nAssume that two matrices multiply together as `AB = C`.\r\n**You need to write out each entries of the product, and then place this entry with a row of A and a column of B which numbered as subscriptions of this entry.**\r\ne.g., in the `Product Matrix`, C₁₁ represents `Row-1 of A multiplies Column-1 of B`;\r\nC₂₁ represents `Row-2 of A multiplies Column-1 of B`.\r\nSo on and so forth, write down all the **entries** of the product entries, and then use `dot product` to calculate each one. \r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39535582-def1e1ea-4e66-11e8-8ce8-26dfac365f3d.png)\r\n\r\n## `Properties of matrix multiplication`\r\n\r\n[Refer to Khan academy article.](https://www.khanacademy.org/math/algebra-home/alg-matrices/modal/a/properties-of-matrix-multiplication)\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39564456-e4ba295e-4ee6-11e8-89fa-5347281decc4.png)\r\n\r\n## `Einstein summation convention`\r\n[Refer to Wiki: Einstein notation](https://en.wikipedia.org/wiki/Einstein_notation)\r\n![image](https://user-images.githubusercontent.com/14041622/39742544-75cdc4d6-52d0-11e8-8fb4-b5b7da2f6380.png)\r\n"},{"url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/comments/386182390","html_url":"https://github.com/solomonxie/solomonxie.github.io/issues/40#issuecomment-386182390","issue_url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/40","id":386182390,"user":{"login":"solomonxie","id":14041622,"avatar_url":"https://avatars2.githubusercontent.com/u/14041622?v=4","gravatar_id":"","url":"https://api.github.com/users/solomonxie","html_url":"https://github.com/solomonxie","followers_url":"https://api.github.com/users/solomonxie/followers","following_url":"https://api.github.com/users/solomonxie/following{/other_user}","gists_url":"https://api.github.com/users/solomonxie/gists{/gist_id}","starred_url":"https://api.github.com/users/solomonxie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/solomonxie/subscriptions","organizations_url":"https://api.github.com/users/solomonxie/orgs","repos_url":"https://api.github.com/users/solomonxie/repos","events_url":"https://api.github.com/users/solomonxie/events{/privacy}","received_events_url":"https://api.github.com/users/solomonxie/received_events","type":"User","site_admin":false},"created_at":"2018-05-03T03:22:40Z","updated_at":"2018-05-04T16:23:18Z","author_association":"OWNER","body":"# MIT OCW 18.06 SC Unit 1.2 Elimination with Matrices\r\n> `Elimination` is the method **EVERY** softwares use to solve `linear equations`.\r\n\r\nprerequisites:\r\n- Terminology(Augmented matrix, elementary matrix, pivot, gauss elimination...), included in [this note](https://github.com/solomonxie/solomonxie.github.io/issues/40#issuecomment-383020020).\r\n- Matrix elimination, review [this note](https://github.com/solomonxie/solomonxie.github.io/issues/40#issuecomment-383020020).\r\n- Gauss elimination, review in simple wiki.\r\n\r\nLecture video timeline | Links\r\n-- | -- \r\nLecture | [0:00](https://www.youtube.com/watch?v=QVKj3LADCnA&t=0s&index=2&list=PLE7DDD91010BC51F8)\r\nElimination pivots and an example | [3:09](https://youtu.be/QVKj3LADCnA?t=3m9s) \r\nFailure of Elimination method | [10:34](https://youtu.be/QVKj3LADCnA?t=10m34s) \r\nAugmented matrix | [14:50](https://youtu.be/QVKj3LADCnA?t=14m50s)\r\nOperations of matrices elimination | [19:24](https://youtu.be/QVKj3LADCnA?t=19m24s)\r\nRow operations of Matrices Multiplication | [20:22](https://youtu.be/QVKj3LADCnA?t=20m22s)\r\nColumn operations of Matrices multiplication | [21:43](https://youtu.be/QVKj3LADCnA?t=21m43s)\r\nElementary Matrix | [24:46](https://youtu.be/QVKj3LADCnA?t=24m46s)\r\nInclude all elimination steps in one Matrix | [33:29](https://youtu.be/QVKj3LADCnA?t=33m29s)\r\n\r\n> To do `column operations`, the matrix multiplies on the right. To do `row operations`, the matrix multiplies on the left.\r\n\r\n## `Column operation` of Matrices Multiplication\r\n\r\n> Below it's a `Column Vector multiplied by a 3x3 Matrix`:\r\n![image](https://user-images.githubusercontent.com/14041622/39472961-f1dfd32c-4d7e-11e8-8c0f-2ebf560526d0.png)\r\n\r\nThe result  above is a `3x1 Matrix`, which is a `Column vector` again. Because:\r\n\r\n**THE RESULT OF THAT COLUMN OPERATION IS A LINEAR COMBINATIONS OF THE COLUMNS.**\r\n\r\n> **\"A MATRIX TIMES A COLUMN, IS A COLUMN.\"**\r\n\r\n\r\n## `Row operation` of Matrices Multiplication\r\n\r\n> Below it's a `Row Vector to multiply a 3x3 Matrix`:\r\n![image](https://user-images.githubusercontent.com/14041622/39472895-a9e5568c-4d7e-11e8-9d75-07d5224a3f42.png)\r\n\r\nThe result above is a `1x3 Matrix`, which is a `Row vector` again. Because:\r\n\r\n**THE RESULT OF THAT ROW OPERATION IS A COMBINATION OF THE ROWS.**\r\n\r\n\r\n## `Elementary Matrix`\r\n> It's also called `Elimination Matrix`.\r\n\r\n[Refer to this amazing good video by Mathispower4u: Elementary Matrices](https://www.youtube.com/watch?v=7H3JFH3IjB0&feature=youtu.be)\r\n[Refer to Mathispower4u: Write a Matrix as a Product of Elementary Matrices](https://www.youtube.com/watch?v=pMp8RfWtPwQ&feature=youtu.be)\r\n\r\nSimply saying, an `Elementary Matrix` is just an `Identity Matrix` with **ONLY ONE ELEMENT CHANGED**.\r\n\r\n`Elementary Matrix` must be **ONLY ONE ROW OPERATION** away from the `Identity Matrix`.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39473567-0bc69f66-4d82-11e8-98d9-d7ff9f49760d.png)\r\n\r\nThe example above is an `elementary matrix` which only altered the `Row-2 Column-1 entry`, and we'd like to call it the `E₂₁ matrix`, which represents `the elementary matrix which fixed the 2-1 position`.\r\n\r\nThe reason we need an `elementary matrix` is to apply each one step of `Elimination of linear equations`.\r\nWhich means that, \r\n\r\n**FOR EVERY SINGLE STEP OF ELIMINATION, WE NEED AN ELEMENTARY MATRIX.**\r\n\r\nSo for **two steps of elimination**, we could represent it with `elementary matrices` as below:\r\n![image](https://user-images.githubusercontent.com/14041622/39473976-4b9e3534-4d84-11e8-90bf-4dc88a5ef825.png)\r\n\r\nCombining **all elimination steps** in ONE MATRIX:\r\n![image](https://user-images.githubusercontent.com/14041622/39474381-4f43ebf0-4d86-11e8-8b0e-6d3788d67616.png)\r\n\r\n## `Permutation Matrix`\r\n> `Permutation Matrix` is **ANOTHER TYPE OF ELEMENTARY MATRIX**, and used only to **switch positions** of elements in the matrix, without changing any numbers.\r\n\r\nReview [Dr. Strang's lecture](https://www.youtube.com/watch?v=QVKj3LADCnA&feature=youtu.be&t=36m42s).\r\n\r\nExample: To **switch two ROWS of a matrix** by using a `permutation matrix` :\r\n![image](https://user-images.githubusercontent.com/14041622/39474697-cc77de32-4d87-11e8-90ba-f7cff7edd486.png)\r\n\r\nExample: To **switch two COLUMNS of a matrix** by using a `permutation matrix`:\r\n![image](https://user-images.githubusercontent.com/14041622/39474756-113f76b0-4d88-11e8-950a-719ba2619094.png)\r\n\r\n### `Some common permutation matrices`\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39619697-5605a320-4fbb-11e8-89b6-51a9490314c7.png)\r\n\r\n"},{"url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/comments/386182431","html_url":"https://github.com/solomonxie/solomonxie.github.io/issues/40#issuecomment-386182431","issue_url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/40","id":386182431,"user":{"login":"solomonxie","id":14041622,"avatar_url":"https://avatars2.githubusercontent.com/u/14041622?v=4","gravatar_id":"","url":"https://api.github.com/users/solomonxie","html_url":"https://github.com/solomonxie","followers_url":"https://api.github.com/users/solomonxie/followers","following_url":"https://api.github.com/users/solomonxie/following{/other_user}","gists_url":"https://api.github.com/users/solomonxie/gists{/gist_id}","starred_url":"https://api.github.com/users/solomonxie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/solomonxie/subscriptions","organizations_url":"https://api.github.com/users/solomonxie/orgs","repos_url":"https://api.github.com/users/solomonxie/repos","events_url":"https://api.github.com/users/solomonxie/events{/privacy}","received_events_url":"https://api.github.com/users/solomonxie/received_events","type":"User","site_admin":false},"created_at":"2018-05-03T03:23:00Z","updated_at":"2018-05-07T15:15:18Z","author_association":"OWNER","body":"# MIT OCW 18.06 SC  Unit 1.3 Multiplication & Inverse Matrices\r\n\r\nPrerequisites | Links\r\n-- | --\r\nMatrix multiplication basics(row * col) | [Note](https://github.com/solomonxie/solomonxie.github.io/issues/40#issuecomment-386033645)\r\nElementary matrices | [Video](https://www.youtube.com/watch?v=1SoU0BfhKaI&feature=youtu.be)\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39558587-692a7a7e-4ec2-11e8-86ed-81f3087d761a.png)\r\n\r\n[Refer to Juanklopper's jupyter notebook.](https://github.com/solomonxie/jupyter-notebooks/blob/master/forks/MIT_OCW_Linear_Algebra_18_06-master/I_04_Matrix_multiplication_Inverses.ipynb)\r\n\r\nLecture timeline | Links\r\n-- | --\r\nLecture | [0:0](https://www.youtube.com/watch?v=FX4C-JpTFgY&t=136s&index=3&list=PLE7DDD91010BC51F8)\r\nMethod 1: Multiply matrix by vector | [0:50](https://youtu.be/FX4C-JpTFgY?t=50s)\r\nWhen allowed to multiply matrices | [4:38](https://youtu.be/FX4C-JpTFgY?t=4m38s)\r\nMethod 2: Multiply matrix by COLUMN | [6:12](https://youtu.be/FX4C-JpTFgY?t=6m12s)\r\nMethod 3: Multiply ROW by matrix | [10:04](https://youtu.be/FX4C-JpTFgY?t=10m4s)\r\nMethod 4: Multiply COLUMN by ROW | [11:37](https://youtu.be/FX4C-JpTFgY?t=11m37s)\r\nMethod 5: Block Multiplication | [18:25](https://youtu.be/FX4C-JpTFgY?t=18m25s)\r\nInverse Matrices (Square matrices) | [21:15](https://youtu.be/FX4C-JpTFgY?t=21m15s)\r\nInvertible Matrix | [22:00](https://youtu.be/FX4C-JpTFgY?t=22m)\r\nSingular Matrix (No-inverse matrix) | [24:39](https://youtu.be/FX4C-JpTFgY?t=24m39s)\r\nCalculate Inverse of Matrix | [31:52](https://youtu.be/FX4C-JpTFgY?t=31m52s)\r\nGauss-Jordan Elimination to solve Inverse of a matrix | [35:20](https://youtu.be/FX4C-JpTFgY?t=35m20s)\r\n\r\n\r\n## `Method 1: Multiply matrix by vector`\r\n\r\nCalculation of an entry of the Product Matrix.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39560053-60299bb6-4ecd-11e8-988c-c8359b65fdbc.png)\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39558944-429fcc62-4ec5-11e8-809b-8be93a1660cb.png)\r\n\r\n## `Method 2: Multiply matrix by COLUMN`\r\n\r\nEach **column** of the `product matrix C`, is `Matrix A * Column of B`.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39559663-7857ec9a-4eca-11e8-9a71-c969fa48bac6.png)\r\n\r\n## `Method 3: Multiply ROW by matrix`\r\n\r\nEach **row** of the `product matrix C`, is `Row of A * Matrix B`.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39559794-77f07a8c-4ecb-11e8-82af-4cdd8c8d9821.png)\r\n\r\n\r\n## `Method 4: Multiply COLUMN by ROW`\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39559955-ab9ad82c-4ecc-11e8-9d7e-790b76d79975.png)\r\n\r\n### `Dot product`\r\n![image](https://user-images.githubusercontent.com/14041622/39560005-08e11582-4ecd-11e8-8f10-53322d584bb3.png)\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39709443-6a62c152-524c-11e8-9137-23904f5b6d5a.png)\r\n\r\n## `Method 5: Block multiplication`\r\n\r\nYou can cut each matrix to blocks, each block is no necessary to be equal sized as long as they can match each other well.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39560231-e0a54096-4ece-11e8-99c7-5d64c5e739ad.png)\r\n\r\nAfter you cut matrices into blocks, the multiplication will just be like a smaller matrix multiplication: **Each block can be seen as a number in a matrix.**\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39560200-a36da5f6-4ece-11e8-9c9b-c729f0418abd.png)\r\n\r\n## `Inverses (Square matrices)`\r\n\r\nIf a matrix's inverse exists, then we call this matrix `Invertible`, or `Non-singular`.\r\n\r\nAnd only with `square matrices`, the inverse can be both **right side** or **left side** with the original matrix to produce the `Identity Matrix`.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39560342-d9d403f0-4ecf-11e8-8526-c704ad2d4811.png)\r\n\r\n### `Singular Matrix (No inverse)`\r\n\r\nSimplest way to tell if it's a `singular matrix` is to calculate its `Determinant` which we learnt in high school: It's a singular matrix if its determinant is ZERO.\r\nBut there's another way to tell:\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39560934-b1d24c04-4ed4-11e8-9d8c-c0331fc8b2db.png)\r\n\r\n\r\n## `Use Gauss-Jordan Elimination to get Inverse`\r\n\r\n**THIS METHOD IS SO MUCH EASIER TO GET THE INVERSE THAN THE WAY WE LEARNT IN HIGH SHCOOL WHICH LETS YOU TO CALCULATE ALL DETERMINANT, ADJUGATE AND COFACTOR AND SO ON.**\r\n\r\n[Refer to Khan academy lecture: Inverting a 3x3 matrix using Gaussian elimination.](https://www.khanacademy.org/math/algebra-home/alg-matrices/alg-determinants-and-inverses-of-large-matrices/v/inverting-matrices-part-3)\r\n\r\n[Online Calculator.](https://www.symbolab.com/solver/step-by-step/inverse%20%5Cbegin%7Bpmatrix%7D1%262%261%5C%5C%202%260%260%5C%5C%200%260%262%5Cend%7Bpmatrix%7D)\r\n\r\nPractice for Gauss-Jordan Elimination to get Inverse of a matrix:\r\n- [ ] [Khan academy](https://www.khanacademy.org/math/algebra-home/alg-matrices/alg-determinants-and-inverses-of-large-matrices/e/matrix_inverse_3x3)\r\n- [ ] [Symbolab](https://www.symbolab.com/practice/matrices-practice#area=main&subtopic=Inverse&isTour=false)\r\n- [ ] [Wolfram](https://www.wolframalpha.com/problem-generator/quiz/?category=Linear%20algebra&topic=Inverse2Matrix)\r\n- [ ] [UOS](http://www.maths.usyd.edu.au/u/UG/JM/MATH1002/Quizzes/quiz8.html)\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39561075-e257821c-4ed5-11e8-922d-8158a6587525.png)\r\n\r\nWith this formula above, we got TWO equations, which will help us form a **system of equations**!\r\nThat's where Gauss comes in: we **AUGMENT TWO COLUMNS** to the matrix.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39561501-a6a297d6-4ed8-11e8-9a18-f92b4b309ad2.png)\r\n\r\nWhy could we use Gauss-Jordan Elimination to solve `Inverse of matrix`?\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39561633-7483dae8-4ed9-11e8-996c-703cc2fcabb4.png)\r\n\r\nThe `E` above represents `all elementary matrices`.\r\n\r\n[For refreshing `how to get elementary matrices` please refer to this video by mathispower4u](https://www.youtube.com/watch?v=1SoU0BfhKaI&feature=youtu.be)\r\n![image](https://user-images.githubusercontent.com/14041622/39562501-89d4b1d8-4ede-11e8-8b38-b46d31ee20cb.png)\r\n"},{"url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/comments/386210066","html_url":"https://github.com/solomonxie/solomonxie.github.io/issues/40#issuecomment-386210066","issue_url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/40","id":386210066,"user":{"login":"solomonxie","id":14041622,"avatar_url":"https://avatars2.githubusercontent.com/u/14041622?v=4","gravatar_id":"","url":"https://api.github.com/users/solomonxie","html_url":"https://github.com/solomonxie","followers_url":"https://api.github.com/users/solomonxie/followers","following_url":"https://api.github.com/users/solomonxie/following{/other_user}","gists_url":"https://api.github.com/users/solomonxie/gists{/gist_id}","starred_url":"https://api.github.com/users/solomonxie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/solomonxie/subscriptions","organizations_url":"https://api.github.com/users/solomonxie/orgs","repos_url":"https://api.github.com/users/solomonxie/repos","events_url":"https://api.github.com/users/solomonxie/events{/privacy}","received_events_url":"https://api.github.com/users/solomonxie/received_events","type":"User","site_admin":false},"created_at":"2018-05-03T07:19:10Z","updated_at":"2018-05-04T16:22:09Z","author_association":"OWNER","body":"# MIT OCW 18.06 SC  Unit 1.4 Factorization into A = LU\r\n\r\nPrerequisites\r\n-- |\r\nMatrix Inverses |\r\nMatrix multiplication |\r\nElementary Matrix |\r\nPermutation Matrix |\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39564033-17aaeb3e-4ee5-11e8-9bd9-d998edfad405.png)\r\n\r\nLecture timeline | Links\r\n-- | --\r\nLecture | [0:00](https://www.youtube.com/watch?v=MsIvs_6vC38&t=130s&index=4&list=PLE7DDD91010BC51F8)\r\nWhat's the Inverse of a Product | [0:25](https://youtu.be/MsIvs_6vC38?t=25s)\r\nInverse of a Transposed Matrix | [4:02](https://youtu.be/MsIvs_6vC38?t=4m2s)\r\nHow's A related to U | [7:51](https://youtu.be/MsIvs_6vC38?t=7m51s)\r\n3x3 LU Decomposition (without Row Exchange) | [13:53](https://youtu.be/MsIvs_6vC38?t=13m53s)\r\nL is product of inverses | [16:45](https://youtu.be/MsIvs_6vC38?t=16m45s)\r\nHow expensive is Elimination | [26:05](https://youtu.be/MsIvs_6vC38?t=26m5s)\r\nLU Decomposition (with Row exchange) | [40:18](https://youtu.be/MsIvs_6vC38?t=40m18s)\r\nPermutations for Row exchanges | [41:15](https://youtu.be/MsIvs_6vC38?t=41m15s)\r\n\r\n\r\n> \"`A = LU` is the BIG FORMULA for elimination. It's a great way to look at Gaussian Elimination.\"\r\n\r\n## `What's the Inverse of a product`\r\nAssume `A & B` are all invertible matrices, so what is `(AB)⁻¹`?\r\n\r\nYes, we multiply their inverses together `A⁻¹ & B⁻¹`, but in what order do we multiply these inverses?\r\n**IN REVERSE ORDER.**\r\nWhich makes:\r\n`(AB)(B⁻¹A⁻¹) = 𝐈` or `(B⁻¹A⁻¹)(AB) = 𝐈`. They perform in the same way get the same result.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39616176-bbd17dc8-4fac-11e8-99ca-ef76bd1bc55b.png)\r\nso:\r\n\r\n**`(AB)⁻¹ = (B⁻¹A⁻¹)`**\r\n\r\n\r\n## `Inverse of a Transposed Matrix`\r\n![image](https://user-images.githubusercontent.com/14041622/39616136-80e71ede-4fac-11e8-87a6-e22360a42818.png)\r\n\r\nSo the Inverse of `(Aᵀ)⁻¹ = (A⁻¹)ᵀ`\r\n\r\n\r\n## `LU Decompose (without Row Exhcnage)`\r\n\r\n> \"L is the product of Inverses.\"\r\n\r\n**`L = E⁻¹`, which means L is the inverse of `elementary matrix`.**\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39617446-580782dc-4fb2-11e8-8ed5-99b2e45cf696.png)\r\n\r\nAssume in the elimination process without row exchanges, we only apply `elementary matrices` to the matrix one by one.\r\nSo the `L` would be the **Inverse** of those elementary matrices, but in **Reverse order**.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39617696-45d219b4-4fb3-11e8-87e0-18d5dcec3dde.png)\r\n\r\n```py\r\nEA = U\r\nA = LU\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39618742-b5a2062e-4fb7-11e8-9fbc-b715793b9963.png)\r\n\r\n> So that steps above is the `Inverse Elementary Matrices` picture of getting the L. \r\nBut actually what actually we get is really simple to observe:\r\n**If no row exchanges, multipliers go directly into L.**\r\n\r\nSo as we've understood the meaning behind it, we can forget it and just remember the **`multipliers`**.\r\n\r\n\r\n## `Row exchanges with Permutations`\r\n> For LU Decomposition, although we can't represent row exchanges with `Elementary Matrices`, but we can do it with `Permutation matrices`.\r\n\r\nFor a 3x3 Identity Matrix, there're 6 permutations of it:\r\n![image](https://user-images.githubusercontent.com/14041622/39620002-460a70a8-4fbc-11e8-8e4b-5ee3ef3b9f7f.png)\r\n\r\n\r\n**The `Inverse of a Permutation` is its `Transpose`**:\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39619970-2c5b12c0-4fbc-11e8-9cef-03ac2fc3238d.png)\r\n"},{"url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/comments/386260109","html_url":"https://github.com/solomonxie/solomonxie.github.io/issues/40#issuecomment-386260109","issue_url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/40","id":386260109,"user":{"login":"solomonxie","id":14041622,"avatar_url":"https://avatars2.githubusercontent.com/u/14041622?v=4","gravatar_id":"","url":"https://api.github.com/users/solomonxie","html_url":"https://github.com/solomonxie","followers_url":"https://api.github.com/users/solomonxie/followers","following_url":"https://api.github.com/users/solomonxie/following{/other_user}","gists_url":"https://api.github.com/users/solomonxie/gists{/gist_id}","starred_url":"https://api.github.com/users/solomonxie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/solomonxie/subscriptions","organizations_url":"https://api.github.com/users/solomonxie/orgs","repos_url":"https://api.github.com/users/solomonxie/repos","events_url":"https://api.github.com/users/solomonxie/events{/privacy}","received_events_url":"https://api.github.com/users/solomonxie/received_events","type":"User","site_admin":false},"created_at":"2018-05-03T11:06:40Z","updated_at":"2018-05-03T16:44:00Z","author_association":"OWNER","body":"# `LU Decomposition`\r\n\r\nFor a Matrix A, we could factor it out as `A = LU`, just like we factor a number to two numbers.\r\n\r\n[`Online LU Decomposition Calculator`](https://www.wolframalpha.com/input/?i=LU+decomposition+of+%7B%7B7,3,-11%7D,%7B-6,7,10%7D,%7B-11,2,-2%7D%7D&lk=3)\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39573271-176de746-4f05-11e8-9309-26d7d0f664ac.png)\r\n\r\n## `Upper Triangular Matrix`\r\n\r\nThe factor matrix `U` represents the `Upper Triangular Matrix`, which we're already familiar with: the matrix we've got after `Gauss Elimination`.\r\n\r\nRefer to video:[ LU Decomposition using Gaussian Elimination](https://www.youtube.com/watch?v=jbeX2HCW6OE)\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39575064-d1531996-4f0b-11e8-995e-239df4d1214a.png)\r\n\r\n\r\n## `Lower Triangular Matrix`\r\n\r\nThe factor matrix `L` is not hard to get as well: \r\n**All the numbers in this matrix are `factor numbers` we used in each elimination step.**\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39574447-d81f9198-4f09-11e8-946d-1f1274111884.png)\r\n\r\n### `How to get the Lower Triangular Matrix`\r\n\r\n[Refer to this video: LU Decomposition - Shortcut Method by Math is power](https://www.youtube.com/watch?v=UlWcofkUDDU)\r\n\r\n\r\n## `Solve System of equations using LU Decomposition`\r\n> The final **goal** of learning `LU Decomposition` is to **solve Linear systems**.\r\n\r\n[Refer to this video: Solve a System of Linear Equations Using LU Decomposition](https://www.youtube.com/watch?v=m3EojSAgIao&feature=youtu.be)\r\n\r\nAssume there's equation `AX = B` as below, and we're to solve for `X`: \r\n![image](https://user-images.githubusercontent.com/14041622/39588763-ffebdd56-4f2e-11e8-8a07-891176ba45e8.png)\r\n\r\nSteps to apply the `LU Decomposition` to solve the Linear System:\r\n- Decompose LU, and represent `AX = B` as `LUX = B`\r\n![image](https://user-images.githubusercontent.com/14041622/39590029-47d16bf6-4f32-11e8-9fec-3c8b8f69b577.png)\r\n- Let `Y = UX`, then solve `LY = B` for `Y`\r\n![image](https://user-images.githubusercontent.com/14041622/39589780-b2228144-4f31-11e8-93f7-29aecf55d008.png)\r\n- Solve `Y = UX` for `X`\r\n![image](https://user-images.githubusercontent.com/14041622/39589848-e32dfdf4-4f31-11e8-8856-20deeb25fc7b.png)\r\n\r\n\r\n\r\n"},{"url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/comments/386550413","html_url":"https://github.com/solomonxie/solomonxie.github.io/issues/40#issuecomment-386550413","issue_url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/40","id":386550413,"user":{"login":"solomonxie","id":14041622,"avatar_url":"https://avatars2.githubusercontent.com/u/14041622?v=4","gravatar_id":"","url":"https://api.github.com/users/solomonxie","html_url":"https://github.com/solomonxie","followers_url":"https://api.github.com/users/solomonxie/followers","following_url":"https://api.github.com/users/solomonxie/following{/other_user}","gists_url":"https://api.github.com/users/solomonxie/gists{/gist_id}","starred_url":"https://api.github.com/users/solomonxie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/solomonxie/subscriptions","organizations_url":"https://api.github.com/users/solomonxie/orgs","repos_url":"https://api.github.com/users/solomonxie/repos","events_url":"https://api.github.com/users/solomonxie/events{/privacy}","received_events_url":"https://api.github.com/users/solomonxie/received_events","type":"User","site_admin":false},"created_at":"2018-05-04T09:34:06Z","updated_at":"2018-05-08T06:42:56Z","author_association":"OWNER","body":"# MIT OCW 18.06 SC  Unit 1.5 Transposes, Permutations, Vector Spaces Rⁿ\r\n\r\nLecture timeline | Links\r\n-- | --\r\nLecture | [0:00](https://www.youtube.com/watch?v=JibVXBElKL0&list=PLE7DDD91010BC51F8&index=5&t=0s)\r\nPermutations | [1:17](https://youtu.be/JibVXBElKL0?t=1m17s)\r\nPossibilities of permutations | [7:23](https://youtu.be/JibVXBElKL0?t=7m23s)\r\nTransposes | [10:15](https://youtu.be/JibVXBElKL0?t=10m15s)\r\nGeneral formula for transpose | [11:38](https://youtu.be/JibVXBElKL0?t=11m38s)\r\nSymmetric matrices | [12:43](https://youtu.be/JibVXBElKL0?t=12m43s)\r\nRᵀR is always symmetric | [15:06](https://youtu.be/JibVXBElKL0?t=15m6s)\r\nChapter 3: Vector spaces | [20:12](https://youtu.be/JibVXBElKL0?t=20m12s)\r\nWhat \"space\" means | [22:03](https://youtu.be/JibVXBElKL0?t=22m3s)\r\nWhy is Origin necessary in Vector spaces | [25:33](https://youtu.be/JibVXBElKL0?t=25m33s)\r\nMost important thing about Vector space | [28:29](https://youtu.be/JibVXBElKL0?t=28m29s)\r\nA case that's not a Vector space | [29:41](https://youtu.be/JibVXBElKL0?t=29m41s)\r\nAll possible subspaces in R² | [35:54](https://youtu.be/JibVXBElKL0?t=35m54s)\r\nAll possible subspaces in R³ | [39:04](https://youtu.be/JibVXBElKL0?t=39m4s)\r\nSubspaces come out from Matrices: Column Space | [39:45](https://youtu.be/JibVXBElKL0?t=39m45s)\r\n\r\n\r\n## `Permutations`\r\n> \"Permutation executes Row exchanges.\"\r\n\r\nFor LU Decomposition the `A = LU` **DOESN'T** work with `Row exchanges`, so we change it to:\r\n```py\r\nPA = LU\r\n\r\n# P = Permutation Matrix = Identity Matrix with Reordered rows\r\n```\r\n**Which apply row exchanges to matrix A into the right order (for pivots), then decompose it.**\r\n\r\n### Permutation properties\r\n```py\r\nPossibilities of Permutations of nxn matrix = n!\r\n\r\nP⁻¹ = Pᵀ\r\nPᵀP = 𝐈\r\n```\r\n\r\n## `Transposes`\r\n\r\nThe way to do a transpose is just **SWITCH ENTRIES**.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39621993-394e1278-4fc3-11e8-827a-776bceb20e4f.png)\r\n\r\n> Remember: intuitively the matrix is **NOT Rotating** to be a transpose, but **Flipping** by the Diagonal of the matrix. Which means the entries on the **DIAGONAL** maintain the same.\r\n![200px-matrix_transpose](https://user-images.githubusercontent.com/14041622/39741457-9f7ff456-52cc-11e8-8d4b-2b1a42e15fc7.gif)\r\n\r\n### `Properties of Transposes`\r\n![image](https://user-images.githubusercontent.com/14041622/39741716-86361f88-52cd-11e8-9749-2d12588f05ef.png)\r\n\r\n### `Special transpose matrices`\r\n> There're some well-known matrices are defined by their Transpose.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39741875-08697928-52ce-11e8-922d-ef4e8a578f0a.png)\r\n\r\n\r\n## `Symmetric matrices`\r\n> It means the transpose of the matrix doesn't change it.\r\n\r\n```py\r\n#symmetric matrix\r\nAᵀ = A\r\n```\r\n\r\nGiven any matrix R (not necessarily square) the product RᵀR is always symmetric, because after transposing it's still the same: \r\n```py\r\n(RᵀR)ᵀ = Rᵀ(Rᵀ)ᵀ = RᵀR\r\n\r\n# Note: (Rᵀ)ᵀ = R, and matrix multiplications is from right to left.\r\n```\r\n\r\n\r\n## `Vector spaces`\r\n\r\n### Most important thing about vector spaces\r\n**We can do operations to any vector and still in the same space.**\r\nWe can add or scale or combine any R² vectors and we're still in R² space. \r\n\r\nIn another word, if you do some additions or scalings to a vector but turns out it jump out of the space, then **It can't be a vector space.**\r\ne.g., take the **positive part of R²** as a space, if we do additions to the vectors in it they will still be positive. BUT, if we apply a **negative scalars** to vectors, they will come out of the **positive space**. So it's not a Vector space.\r\n\r\n**EVERY VECTOR SPACE GOT TO HAVE THE ZERO VECTOR IN IT.**\r\n\r\n### Rules of Vector spaces\r\n\r\n[Refer to video by TheTrevTutor: Vector Spaces](https://www.youtube.com/watch?v=XDvSsDsLVLs&list=PLDDGPdw7e6AjJacaEe9awozSaOou-NIx_&index=27&t=0s)\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39636060-b0124ef0-4ff1-11e8-9a0f-dbf82d5f8875.png)\r\n\r\n\r\n## `Subspaces`\r\nIf a Vector space is **INSIDE** of a Vector space e.g. R², we call it `The Subspace of R²`.\r\n\r\nAll Subspaces of R² | All Subspaces of R³\r\n-- | --\r\nThe whole R² space | The whole R³ space\r\n_-_ | Any plane goes through the Origin `(0,0)`\r\nAny line goes through Origin `(0,0)` | Any line goes through Origin `(0,0,0)`\r\nThe Zero vector itself (𝐙) | The Zero vector itself (𝐙)\r\n\r\nRemember the NO.1 rule of a Subspace:\r\n**ALL VECTOR COMBINATIONS FORM A SUBSPACE.**\r\n\r\n### Three rules of Subspace:\r\n- [ ] Contains Zero vector\r\n- [ ] Closed under addition\r\n- [ ] Closed under scalar multiplication\r\n\r\n## `Column Space`\r\n> Column space is a special kind of subspace, which comes out of **matrix**.\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39627729-69449f72-4fd9-11e8-9359-eb3f76c275d5.png)\r\n![image](https://user-images.githubusercontent.com/14041622/39627899-e3184ba0-4fd9-11e8-9a19-f6720bdee709.png)\r\n\r\n**Which means the column space of a matrix only have 3 vectors: 2 column vectors and a Zero vector, and the Column space(their linear combinations) forms a 2D plane.**"},{"url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/comments/386639070","html_url":"https://github.com/solomonxie/solomonxie.github.io/issues/40#issuecomment-386639070","issue_url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/40","id":386639070,"user":{"login":"solomonxie","id":14041622,"avatar_url":"https://avatars2.githubusercontent.com/u/14041622?v=4","gravatar_id":"","url":"https://api.github.com/users/solomonxie","html_url":"https://github.com/solomonxie","followers_url":"https://api.github.com/users/solomonxie/followers","following_url":"https://api.github.com/users/solomonxie/following{/other_user}","gists_url":"https://api.github.com/users/solomonxie/gists{/gist_id}","starred_url":"https://api.github.com/users/solomonxie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/solomonxie/subscriptions","organizations_url":"https://api.github.com/users/solomonxie/orgs","repos_url":"https://api.github.com/users/solomonxie/repos","events_url":"https://api.github.com/users/solomonxie/events{/privacy}","received_events_url":"https://api.github.com/users/solomonxie/received_events","type":"User","site_admin":false},"created_at":"2018-05-04T15:34:23Z","updated_at":"2018-05-05T08:59:05Z","author_association":"OWNER","body":"# MIT OCW 18.06 SC  Unit 1.6Column Space and Nullspace\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39637014-6d9e29b0-4ff4-11e8-975f-00aa020aedc9.png)\r\n\r\n\r\nLecture timeline | Links\r\n-- | --\r\nLecture | [0:00](https://www.youtube.com/watch?v=8o5Cmfpeo6g&index=6&list=PLE7DDD91010BC51F8&t=161s)\r\nWhat are Vector spaces | [1:05](https://youtu.be/8o5Cmfpeo6g?t=1m5s)\r\nSubspaces of R³ | [2:33](https://youtu.be/8o5Cmfpeo6g?t=2m31s)\r\nIs the union of two subspaces a Subspace? | [4:23](https://youtu.be/8o5Cmfpeo6g?t=4m23s)\r\nColumn space | [11:36](https://youtu.be/8o5Cmfpeo6g?t=11m36s)\r\nFeatures a Column space | [14:46](https://youtu.be/8o5Cmfpeo6g?t=14m46s)\r\nHow much smaller is the Column space? | [15:48](https://youtu.be/8o5Cmfpeo6g?t=15m48s)\r\nDoes every `Ax=B` have a solution for every `B`? | [16:17](https://youtu.be/8o5Cmfpeo6g?t=16m17s)\r\nWhich `B`s allow the system of equations solved | [19:39](https://youtu.be/8o5Cmfpeo6g?t=19m39s)\r\nNull space | [28:12](https://youtu.be/8o5Cmfpeo6g?t=28m12s)\r\nUnderstand what's the point of a Vector space | [40:24](https://youtu.be/8o5Cmfpeo6g?t=40m24s)\r\n\r\n### Is the union of two subspaces a subspace?\r\n![image](https://user-images.githubusercontent.com/14041622/39638399-aab7386a-4ff8-11e8-8a0d-c5e2ce2c5654.png)\r\n\r\n### How to form a Column space\r\nFor a 3x3 matrix,\r\n![image](https://user-images.githubusercontent.com/14041622/39639138-feef6450-4ffa-11e8-9b2b-105178c3026e.png)\r\nWe pick out three Column Vectors, and take all their **`Linear combinations`**, then we formed a **`Column space`**.\r\n\r\n> Definition: Column Space of A is all Linear combinations of A's columns.\r\n\r\n### Does every `Ax=B` have a solution for every `B`?\r\nNO!\r\nNot always, but sometimes.\r\n\r\n> \"The system of linear equations Ax = b is solvable exactly when b is a vector in the column space of A\"\r\n\r\n\r\n## `Null space Ax=0`\r\n![image](https://user-images.githubusercontent.com/14041622/39661357-d072ebe6-5082-11e8-9f3e-f3c952c1df91.png)\r\n\r\n> \"If you give me a Matrix A, and let me to find N(A). Literally my goal is to find the set of All x's satisfied the equation Ax=0.\"\r\n\r\n[Refer to Khan academy lecture](https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/null-column-space/v/introduction-to-the-null-space-of-a-matrix)\r\n[Refer to this video explanation by TheTrevTutor](https://www.youtube.com/watch?v=JlC58uaJVsg&list=PLDDGPdw7e6AjJacaEe9awozSaOou-NIx_&index=32&t=0s)\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39661172-eda0b6e2-507f-11e8-84dd-9b911098fb6d.png)\r\n"},{"url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/comments/386859797","html_url":"https://github.com/solomonxie/solomonxie.github.io/issues/40#issuecomment-386859797","issue_url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/40","id":386859797,"user":{"login":"solomonxie","id":14041622,"avatar_url":"https://avatars2.githubusercontent.com/u/14041622?v=4","gravatar_id":"","url":"https://api.github.com/users/solomonxie","html_url":"https://github.com/solomonxie","followers_url":"https://api.github.com/users/solomonxie/followers","following_url":"https://api.github.com/users/solomonxie/following{/other_user}","gists_url":"https://api.github.com/users/solomonxie/gists{/gist_id}","starred_url":"https://api.github.com/users/solomonxie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/solomonxie/subscriptions","organizations_url":"https://api.github.com/users/solomonxie/orgs","repos_url":"https://api.github.com/users/solomonxie/repos","events_url":"https://api.github.com/users/solomonxie/events{/privacy}","received_events_url":"https://api.github.com/users/solomonxie/received_events","type":"User","site_admin":false},"created_at":"2018-05-06T07:22:57Z","updated_at":"2018-05-07T07:56:28Z","author_association":"OWNER","body":"# `Scalar Projection & Vector Projection`\r\n\r\n[Refer to the note in `Pre Linear algebra` about understanding Dot product.](https://github.com/solomonxie/solomonxie.github.io/issues/48#issuecomment-383118452)\r\n\r\nAssume that the vector `w` projects onto the vector `v`.\r\nNotation:\r\n- Scalar projection: **`Componentᵥw`**, read as \"Component of `w` onto `v`\".\r\n- Vector projection: **`Projectionᵥw`**, read as \"Projection of `w` onto `v`\".\r\n\r\n**Notice that: When you read it, it's in a reverse order! Very important!**\r\n\r\n## Projection Formula\r\n\r\nNote that, the formula concerns of these concepts as **prerequisites**:\r\n- Dot product calculation\r\n- Dot product cosine formula\r\n- Unit vector\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39670502-d6ce9c72-5138-11e8-9996-e2576d1e48b9.png)\r\n\r\n## `How to calculate the Scalar Projection`\r\n> The name is just the same with the names mentioned above: `boosting`.\r\n\r\n```py\r\nComponentᵥw = (dot product of v & w) / (w's length)\r\n```\r\n\r\n[Refer to lecture by Imperial College London: Projection](https://www.youtube.com/watch?v=0bS5_k86id8&index=8&list=PLZnyIsit9AM7acLo1abCA1STjZ41ffwaM)\r\n[Refer also to Khan academy: Intro to Projections](https://www.khanacademy.org/math/linear-algebra/matrix-transformations/lin-trans-examples/v/introduction-to-projections)\r\n\r\nWhat if we know the vectors, and we want to know how much is the `Scalar projection`(the shadow)?\r\nExample:\r\n![image](https://user-images.githubusercontent.com/14041622/39665580-4f346e6e-50c9-11e8-944b-4c771e236ae8.png)\r\nHow we're gonna solve this is: We know the vectors, so we can get their `dot product` easily by taking their linear combination; and we know the length of each vector, by using Pythagorean theorem; and then we get the projection, as in the picture.\r\n\r\n## `How to calculate the Vector Projection`\r\n> It's another idea for projection, and less intuitive.\r\n\r\nRemember that a `Scalar projection` is the vector's **LENGTH** projected on another vector. And when we add the **DIRECTION** onto the LENGTH, it became a vector, which lies on another vector. Then it makes it a `Vector projection`.\r\n\r\nIt can be understood as this formula:\r\n```py\r\nProjectionᵥw = (Componentᵥw) * (Unit vector of v)\r\n```\r\nBut usually we write it as this:\r\n![image](https://user-images.githubusercontent.com/14041622/39691159-2dd0d3ec-520f-11e8-8922-f0c6f8c593ae.png)\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39691134-1d490f4e-520f-11e8-9077-82b63a569303.png)\r\n\r\n\r\n[Refer also to video for formula by Kate Penner: Vector Projection Equations](https://www.youtube.com/watch?v=cZuDWviSI4c)\r\n[Refer to video by Firefly Lectures: Vector Projections - Example 1](https://www.youtube.com/watch?v=xSu-0xcRBo8)\r\n\r\n\r\nExample:\r\n![image](https://user-images.githubusercontent.com/14041622/39665680-7994804e-50ca-11e8-9b3c-22d8eb3a66f4.png)\r\n"},{"url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/comments/386859969","html_url":"https://github.com/solomonxie/solomonxie.github.io/issues/40#issuecomment-386859969","issue_url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/40","id":386859969,"user":{"login":"solomonxie","id":14041622,"avatar_url":"https://avatars2.githubusercontent.com/u/14041622?v=4","gravatar_id":"","url":"https://api.github.com/users/solomonxie","html_url":"https://github.com/solomonxie","followers_url":"https://api.github.com/users/solomonxie/followers","following_url":"https://api.github.com/users/solomonxie/following{/other_user}","gists_url":"https://api.github.com/users/solomonxie/gists{/gist_id}","starred_url":"https://api.github.com/users/solomonxie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/solomonxie/subscriptions","organizations_url":"https://api.github.com/users/solomonxie/orgs","repos_url":"https://api.github.com/users/solomonxie/repos","events_url":"https://api.github.com/users/solomonxie/events{/privacy}","received_events_url":"https://api.github.com/users/solomonxie/received_events","type":"User","site_admin":false},"created_at":"2018-05-06T07:26:07Z","updated_at":"2018-05-07T15:58:17Z","author_association":"OWNER","body":"# Change of basis\r\n> Changing basis of a vector, the vector's length & direction remain the same, but the numbers represent the vector will change, since the meaning of the numbers have changed. \r\nOur goal is to calculate the New numbers in the vector in terms of the new basis.\r\n\r\n[Refer to video by Trefor Bazett: Deriving the Change-of-Basis formula](https://www.youtube.com/watch?v=njvTyIWtxrE)\r\n\r\n## Projection vector method (Only for 90° bases)\r\n> The goal is to write a vector in a new basis.\r\n\r\n[Refer to lecture form Imperial College London: Changing basis](https://www.coursera.org/learn/linear-algebra-machine-learning/lecture/AN3cB/changing-basis)\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39671000-d7209a68-5142-11e8-82fe-8efe64da9587.png)\r\n\r\nRemember the `Projection \r\n\r\nJust to save some words, here's the example and solution:\r\n\r\nExample:\r\n![image](https://user-images.githubusercontent.com/14041622/39670938-be46df30-5141-11e8-9ccb-872090624350.png)\r\nSolution:\r\nThe idea is to take projection of the vector onto both **new basis**, except it's taking only a part of the `projection vector formula`. As in the formula below, it only takes the blue squared part as the number of the new vector's component.\r\n![image](https://user-images.githubusercontent.com/14041622/39691584-9a06699a-5210-11e8-9778-a2c6c0705643.png)\r\n```py\r\nComponent V₁ = (V﹒b₁) / |b₁|² = (5*1 + -1*1) / ( √(1²+1²) )² = 4/2 = 2\r\nComponent V₂ = (V﹒b₂) / |b₂|² = (5*1 + -1*-1) / ( √(1²+(-1)²) )² = 6/2= 3\r\n\r\nV' = (2, 3)\r\n```\r\n\r\n## `Matrices changing basis`\r\n\r\n[Refer to lecture: Matrices changing basis](https://www.coursera.org/learn/linear-algebra-machine-learning/lecture/q8iik/matrices-changing-basis)\r\n[Refer to video: Change of Coordinates Matrix #2](https://www.youtube.com/watch?v=2K6ipONMIgg&t=24s)\r\n\r\n![image](https://user-images.githubusercontent.com/14041622/39711480-6d133e62-5252-11e8-91e5-f694affec82a.png)\r\n"},{"url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/comments/387298066","html_url":"https://github.com/solomonxie/solomonxie.github.io/issues/40#issuecomment-387298066","issue_url":"https://api.github.com/repos/solomonxie/solomonxie.github.io/issues/40","id":387298066,"user":{"login":"solomonxie","id":14041622,"avatar_url":"https://avatars2.githubusercontent.com/u/14041622?v=4","gravatar_id":"","url":"https://api.github.com/users/solomonxie","html_url":"https://github.com/solomonxie","followers_url":"https://api.github.com/users/solomonxie/followers","following_url":"https://api.github.com/users/solomonxie/following{/other_user}","gists_url":"https://api.github.com/users/solomonxie/gists{/gist_id}","starred_url":"https://api.github.com/users/solomonxie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/solomonxie/subscriptions","organizations_url":"https://api.github.com/users/solomonxie/orgs","repos_url":"https://api.github.com/users/solomonxie/repos","events_url":"https://api.github.com/users/solomonxie/events{/privacy}","received_events_url":"https://api.github.com/users/solomonxie/received_events","type":"User","site_admin":false},"created_at":"2018-05-08T06:26:13Z","updated_at":"2018-05-08T07:04:43Z","author_association":"OWNER","body":"# `Orthogonal Matrix`\r\n> It's a **Square Matrix** consisted with **Unit vectors**. Usually it's just **Identity Matrix**.\r\n\r\n[Refer to Wiki: Orthogonal Matrix.](https://en.wikipedia.org/wiki/Orthogonal_matrix)\r\n[Refer to lecture by Imperial College London: Orthogonal Matrices](https://www.coursera.org/learn/linear-algebra-machine-learning/lecture/uYJRz/orthogonal-matrices)\r\n\r\n### `Orthonormal basis`\r\n> If two vectors are **Unit vectors** AND **Orthogonal**(perpendicular) to each other, they will be called `Orthonormal`.\r\nIf they form a set of Basis, they'll be called `Orthonormal basis`.\r\n\r\n[Refer to Wiki: Orthonormality](https://en.wikipedia.org/wiki/Orthonormality)\r\n\r\n### `Transpose of Orthogonal matrix`\r\nIf the Matrix composed with orthonormal basis, then its `transpose` is its `inverse`: \r\n```py\r\nAᵀ = A⁻¹\r\n\r\n# which makes this one true as well\r\nAAᵀ = 𝐈\r\nAᵀA = 𝐈\r\n```\r\n\r\n### `Determinant of Orthogonal matrix`\r\nThe `determinant` of an Orthogonal matrix, **must be** either 1 or -1.\r\nThe -1 determinant means the matrix was flipped around from originally `right-handed` to `left-handed`.\r\n```py\r\n|A| = ±1\r\n```\r\n\r\n## `The Gram–Schmidt process`\r\n> \" My life would probably be easier if I could construct some **orthonormal basis** somehow. And there's a process for doing that which is called the Gram-Schmidt process\" - David Dye, Imperial College London\r\n\r\n[Refer to lecture: The Gram–Schmidt process](https://www.coursera.org/learn/linear-algebra-machine-learning/lecture/28C1t/the-gram-schmidt-process)\r\n"}]