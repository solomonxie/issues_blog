# ❖ Scrapy 入门 [DRAFT]


## 理解Scrapy流程

`Spider` -> `item` -> `Pipline`

其中：
- `Spider`只负责向目标网站，获得response，传给item
- `item`只负责从response中整理数据，变成item字典对象，传给pipline
- `Pipline`只负责把item字典对象转换为ORM，保存到数据库


## Settings 通用设定

Logging:
```py
LOG_LEVEL = 'INFO'  # DEBUG/INFO/ERROR/CRITICAL
LOG_FORMAT = '%(levelname)s: %(message)s'
```


Robot协议遵守（推荐: 不遵守）：
```py
ROBOTSTXT_OBEY = False

```

随机User-Agent:
```py

```


随机Proxy:
```py

```


## Spider爬虫


### 爬虫类型

为了适合各种不同的爬取需求，Scrapy提供了对应各种情况的不同`爬虫基础类`。

[参考官方文档Scrapy：Spiders](https://scrapy.readthedocs.io/en/latest/topics/spiders.html)

![image](https://user-images.githubusercontent.com/14041622/53234529-aae5ee80-36ca-11e9-8581-25092e90adde.png)

其中各自的特点是：
- `Scrapy Spider`: 所有爬虫的基础类。一般用于自定义爬虫来继承，定制性强。
- `Crawl Spider`：通用型爬虫。适合抓取页面所有链接，可以定制`Rule`筛选链接
- `XML Feed Spider`：XML数据爬虫。自带XML解析
- `CSV Feed Spider`：CSV数据爬虫。自带分隔符判断等
- `Sitemap Spider`：Sitemap爬虫
