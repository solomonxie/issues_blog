# `Null Hypothesis Significance Testing`

`Hypothesis Testing` is that we make a claim, a hypothesis about something, and we then make a test and do statistic on it as evidence to **support or against** the hypothesis. 

`Null hypothesis significance testing` is first to assume the hypothesis is true, and 

## `Null Hypothesis` & `Alternative Hypothesis`

Notations:
- H₀: Null Hypothesis (reads `H-knot`)
- Ha: Alternative Hypothesis (reads `H-alternative`)

_Null hypothesis_ is the hypothesis we claimed as our opinion.
_Alternative hypothesis_ is 

## `Significance Level ⍺` (Threshold)

For making a "judge" on wether the hypothesis stands or fails, we need a standard or threshold to judge it, which we called the `Significance Level`, denoted `⍺` (alpha).

There are a few common sets on the _significance level_:
- \<1%: Very strong evidence against our claim.
- \<5%: Strong evidence against our claim.
- \<10%: Weak evidence against our claim.
- \>10%: Little or no evidence against our claim.

![image](https://user-images.githubusercontent.com/14041622/45202814-be340780-b2ac-11e8-9fa0-3b3dc088877b.png)


## `p-value`
> p-value stands for _Probability value_.

_p-value_ tells **how rare** your data is by giving the **probability** of data as **extreme**  as you observed if the _null hypothesis_ was true.

That being said, _p-value_ is the measure of the strength of the evidence against the _null hypothesis_.

p-value is a **`Conditional Probability`**.

[`▶︎ Back to previous note: Conditional Probability`](https://github.com/solomonxie/solomonxie.github.io/issues/50#issuecomment-412445737)


> The smaller the _p-value_, the greater the evidence against the _null hypothesis_.



## How  to do Hypothesis Testing

![image](https://user-images.githubusercontent.com/14041622/45165275-14f6fe00-b227-11e8-97e1-fe7854f01b08.png)
