# `Hardwares for Deep Learning`

## Commands
- Check Storage: `df -h`
- Check CPU: `cat /proc/cpuinfo`
- Check RAM: `cat /proc/meminfo`
- Check GPU: ``

## `Google Colab`
- GPU(12hrs): NVIDIA Tesla K80 GPU × 1
- CPU: Intel(R) Xeon(R) CPU @ 2.30GHz × 1 Core
- RAM: 13GB
- Storage: 33GB

## `AWS p2`
> P2 instances provide up to 16 **NVIDIA K80 GPUs**, 64 vCPUs and 732 GiB of host memory, with a combined 192 GB of GPU memory, 40 thousand parallel processing cores, 70 teraflops of single precision floating point performance, and over 23 teraflops of double precision floating point performance. 
P2 instances also offer GPUDirect™ (peer-to-peer GPU communication) capabilities for up to 16 GPUs, so that multiple GPUs can work together within a single host.

- GPU: NVIDIA Tesla K80 GPU × (1 to 16)
- CPU: Intel Xeon® E5-2686 v4 × (4 to 64)
- RAM: 61G or 488G or 732G 

![image](https://user-images.githubusercontent.com/14041622/44538961-68505300-a735-11e8-9c66-b1b26dcfa533.png)


## `DIY`
### GPU
- [`NVIDIA Tesla K80 GPU`](https://www.amazon.com/Nvidia-Tesla-GDDR5-Cores-Graphic/dp/B00Q7O7PQA): RMB 30,000, VRAM 24GB (GDDR5), 256 Bit

### CPU
- [`Intel Xeon® E5-2686 v4`](https://www.ebay.com/itm/Intel-Xeon-E5-2686-v4-SR2K8-2-30GHz-18-Core-LGA2011-3/323405561085?epid=20005107689&hash=item4b4c793cfd%3Ag%3A6cQAAOSwlQ5baCxE&LH_ItemCondition=3): RMB 12,000, 8 Cores, 1.7GHz