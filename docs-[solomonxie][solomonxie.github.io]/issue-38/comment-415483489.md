# Hardwares for Deep Learning

## `Google Colab`
GPU: NVIDIA Tesla K80 GPU × 1 (12hrs)

## `AWS p2`
> P2 instances provide up to 16 **NVIDIA K80 GPUs**, 64 vCPUs and 732 GiB of host memory, with a combined 192 GB of GPU memory, 40 thousand parallel processing cores, 70 teraflops of single precision floating point performance, and over 23 teraflops of double precision floating point performance. 
P2 instances also offer GPUDirect™ (peer-to-peer GPU communication) capabilities for up to 16 GPUs, so that multiple GPUs can work together within a single host.

![image](https://user-images.githubusercontent.com/14041622/44538961-68505300-a735-11e8-9c66-b1b26dcfa533.png)


## `DIY`
### GPU
- `NVIDIA Tesla K80 GPU`: RMB 25,000