# `R-Squared`
> `R-squared` means **squared residuals**, is also called `SE`, which is **Squared Errors**.

[Refer to Khan academy: R-squared or coefficient of determination](https://www.khanacademy.org/math/ap-statistics/bivariate-data-ap/modal/v/r-squared-or-coefficient-of-determination)

![image](https://user-images.githubusercontent.com/14041622/43886435-449b4764-9bee-11e8-9996-b05c33876e04.png)

`Coefficient of Determinator` (`r²` or `R-squared`):
![image](https://user-images.githubusercontent.com/14041622/43886827-8d98166c-9bef-11e8-8443-45a2830a67e9.png)
(SE_line is `Squared Error from line`, )

- If `SE` (Squared-Error) from the line is **small**   ->   r² close to 1   ->  The line is a **good fit**.
- If `SE` (Squared-Error) from the line is **large**   ->   r² close to 0   ->    The line is **not** a good fit

## Understanding R-squared
[Refer to youtube: 3.2: Linear Regression with Ordinary Least Squares Part 1 - Intelligence and Learning](https://www.youtube.com/watch?v=szXbuO3bVRk)

### Why are we "Squaring correlation coefficient"?


### Why are we adding them together
By adding them we will get the **TOTAL ERRORS**, which is the one we're going to **minimize**.



